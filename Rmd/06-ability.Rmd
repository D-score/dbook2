# Comparing ability {#ch:ability}

```{=html}
<!-- > Author: Iris Eekhout, Stef van Buuren -->
```

Once we identified a satisfactory D-score model, we may calculate the D-score for children from different cohorts and compare their values. This section highlights various techniques and issues for comparing D-score distributions between studies. We will address the following topics:

-   Comparing child development across studies (\@ref(sec:dscores))
-   Precision of the D-score (\@ref(sec:sem))
-   Domain coverage (\@ref(sec:domains))

## Comparing child development across studies {#sec:dscores}

```{r dscoredist, echo=FALSE, fig.cap = '(ref:dscoredist)', screenshot.alt="fig/fig_6.1.png"}
knitr::include_url("https://d-score.org/dbook-apps/gcdgdscores/#display=by_cohort&nrow=1&ncol=1&arr=row&pg=6&labels=cohort&sort=cohort;asc&filter=&sidebar=&fv=", 
  height = "800px")
```

(ref:dscoredist) [D-score distributions by study](https://d-score.org/dbook-apps/gcdgdscores/#display=by_cohort&nrow=1&ncol=1&arr=row&pg=6&labels=cohort&sort=cohort;asc&filter=&sidebar=&fv=) (<https://d-score.org/dbook-apps/gcdgdscores/>).

Figure \@ref(fig:dscoredist) shows the scatterplot of the D-score by age separately for each cohort. Remember from section \@ref(sec:gcdgoverview) that each study selected its own set of instruments to collect the data. The scatterplots demonstrate a significant advance made possible by the D-score: We can plot the developmental scores of children from **different** cohorts, with **different** ages, using **different** instruments, on the **same** vertical axis.

The five blue lines guide the eye. These lines indicate the locations of the -2SD, -1SD, 0SD, +1SD and +2SD quantiles at each age in the combined data. [Section 5.4, in Chapter I](https://d-score.org/dbook1/sec-reference.html) motivates the idea and provides some technical details. We'll come back to these lines in section \@ref(sec:references).

By and large, the data in every study follow the blue lines. Perhaps the most obvious exception is the `GCDG-JAM-STUNTED` cohort, where older children somewhat exceed the D-score range. It is unknown whether this is real, or due to a sub-optimal calibration of the instrument.

```{r dazdist, fig.cap = '(ref:dazdist)', screenshot.alt="fig/fig_6.1a.png"}
knitr::include_url("https://d-score.org/dbook-apps/gcdgdaz/#display=by_cohort&nrow=1&ncol=1&arr=row&pg=6&labels=cohort&sort=cohort;asc&filter=&sidebar=&fv=", 
  height = "800px")
```

(ref:dazdist) [DAZ distributions by study](https://d-score.org/dbook-apps/gcdgdaz/#display=by_cohort&nrow=1&ncol=1&arr=row&pg=6&labels=cohort&sort=cohort;asc&filter=&sidebar=&fv=) (<https://d-score.org/dbook-apps/gcdgdaz/>).

Figure \@ref(fig:dazdist) plots the same data with D-score transformed into age standardized scores (DAZ). Replacing the D-score by the DAZ emphasises the differences both within and between studies. The majority of observations lies between the -2 SD and +2 SD lines in all cohorts. Using DAZ makes is easier to spot deviating trends, e.g., for the Jamaican or Ethiopian data.

## Precision of the D-score {#sec:sem}

The [EAP algorithm](https://d-score.org/dbook1/sec-dscoreestimation.html#eap-algorithm-numerical-example) estimates the D-score from a set of PASS/FAIL scores. The standard deviation of the posterior distribution (or *sem*: standard error of measurement) quantifies the imprecision of the D-score estimate. The *sem* is inversely related to the number of items. Thus, when we administer more milestones, the *sem* of the D-score drops.

```{r semforn, results = 'hide', fig.keep = 'all', fig.cap = '(ref:semforn)', fig.align='center', echo = FALSE, fig.width=6}
ggplot(data = dmetric::model_lean$dscore )+
  geom_smooth(aes(x=n, y=sem), formula = y ~ splines::bs(x, 4), se = FALSE, color = mice::mdc(2))+
  xlab("Number of items administered") +
  ylab("Standard error of measurement")
```

(ref:semforn) Standard error of measurement (*sem*) as a function of the number of items.

Figure \@ref(fig:semforn) shows that the *sem* drops off rapidly when the number of items is low and stabilises after about 35 items. Apart from test length, the precision of the D-score also depends on item information (c.f. section \@ref(sec:iteminformation)). Administering items that are too easy, or too difficult, does not improve precision. The figure suggests that - in practice - a single D-score cannot be more precise than 0.5 D-score units.

```{r semfora, echo=FALSE, fig.cap='(ref:semfora)', fig.keep='all', results='hide', fig.height=7, fig.width=7, fig.align='center'}
# voor individuele metingen
sem_daz <- dmetric::model_lean$dscore %>%
  mutate(agemos = a *12,
         low_d = d - sem,
         high_d = d +sem, 
         low_daz = dscore::daz(low_d, x = a),
         high_daz = dscore::daz(high_d, x = a))


## of dit berekenen via de pooled sem per age group en daarna pas naar daz omzetten
#pooled sem = srqt(sum(sem^2)/(length(sem)-1))
#alleen gaat het dan mis dat de gemiddelde daz soms buiten het inderval komt (in begin maanden vooral)
#>># proberen door between variantie (var(d)) toe te voegen aan de pooling van de varianties
sem_daz_a <- sem_daz %>% 
  mutate(agecat = cut(agemos, breaks = 0:max(agemos, na.rm=TRUE)), 
         agenum = as.numeric(agecat))%>%
  group_by(agenum) %>% 
  summarize (daz = mean(daz, na.rm = TRUE),
             mean_a = mean(a, na.rm=TRUE), #voor omzetting naar daz
             mean_d = mean(d, na.rm = TRUE),
             var_betw = var(d, na.rm = TRUE),
             var_with = sum(sem^2, na.rm = TRUE),
             n =  sum(!is.na(sem))
             ) %>% ungroup() %>%
  mutate(sem_pool = sqrt((var_with + var_betw)/ (n-1)), 
         low_d = mean_d - sem_pool,
         high_d = mean_d + sem_pool,
         mean_daz = dscore::daz(mean_d, x = mean_a),
         low_daz = dscore::daz(low_d, x = mean_a),
         high_daz = dscore::daz(high_d, x = mean_a))

#ggplot(data = sem_daz_a )+
#  geom_point(aes(x=agenum, y=daz)) +
#  geom_errorbar(aes(x = agenum, ymin=low_daz, ymax=high_daz), width=.1)+
#  xlab("age(months)")+
#  ylim(c(-2,2))

ggplot(data = sem_daz_a )+
  geom_point(aes(x=agenum, y=mean_daz)) +
  geom_errorbar(aes(x = agenum, ymin=low_daz, ymax=high_daz), width=.1)+
  xlab("Age (months)") + ylab("DAZ") +
  ylim(c(-2,2))

#ggplot(data = sem_daz_a )+
#  geom_point(aes(x=agenum, y=mean_d)) +
#  geom_errorbar(aes(x = agenum, ymin=low_d, ymax=high_d), width=.1)+
#  xlab("age(months)") + ylab("D-score")


```

(ref:semfora) Mean DAZ $\pm$ *sem* as a function of age.

One may wonder whether the *sem* depends on age. Figure \@ref(fig:semfora) suggests that this is not the case. The average DAZ is close to zero everywhere, as expected. The interval DAZ $\pm$ *sem* will cover the true, but unknown, DAZ in about 68% of the cases. While the interval varies somewhat across ages, there is no systematic age trend.

```{r dscoresems, fig.cap = '(ref:dscoresems)', screenshot.alt="fig/fig_6.4.png"}
#n items per child Netherlands 1 cohort = 8.5
#ids <- gcdg_lean$visit$subjid[which(gcdg_lean$visit$cohort=="GCDG-NLD-SMOCC")]
#itm <- gcdg_lean$itm[which(gcdg_lean$itm$subjid %in% ids),]
#itmn <- itm %>% group_by(subjid, agedays) %>% summarize(n=n())
#summary(itmn)
#p per child on average for Netherlands 1 cohort = 0.8 (median)
#summary(model_lean$dscore$p[which(model_lean$dscore$cohort == "GCDG-NLD-SMOCC")])

#n items per child Colombia cohort = 46
#ids <- gcdg_lean$visit$subjid[which(gcdg_lean$visit$cohort=="GCDG-COL-LT45M")]
#itm <- gcdg_lean$itm[which(gcdg_lean$itm$subjid %in% ids),]
#itmn <- itm %>% group_by(subjid, agedays) %>% summarize(n=n())
#summary(itmn)
#p per child on average for Colombia 1 cohort = 0.63 (median)
#summary(model_lean$dscore$p[which(model_lean$dscore$cohort == "GCDG-COL-LT45M")])
#knitr::include_app("https://tnochildhealthstatistics.shinyapps.io/GCDG_sem/", 
#  height = "700px")
knitr::include_url("https://d-score.org/dbook-apps/gcdgsem/#display=by_cohort&nrow=1&ncol=1&arr=row&pg=6&labels=cohort&sort=cohort;asc&filter=&sidebar=&fv=",
                   height = "800px")
```

(ref:dscoresems) [The standard error of measurement ($sem$) around the age-standardized D-scores (DAZ) per cohort](https://d-score.org/dbook-apps/gcdgsem/#display=by_cohort&nrow=1&ncol=1&arr=row&pg=6&labels=cohort&sort=cohort;asc&filter=&sidebar=&fv=) (<https://d-score.org/dbook-apps/gcdgsem>).

Does precision vary with studies? The answer is yes. Figure \@ref(fig:dscoresems) plots the same information as before but now broken down according to cohort. Individual data points are added to give a feel for the design. The Colombia cohort `GCDG-COL-LT45M` administered the Bayley-III, where each child answered on average 45 items, so the *sem* is small. In contrast, the Dutch cohort GCDG-NLD-SMOCC collected data on a screener consisting of about ten relatively easy milestones, so the *sem* is relatively large. As a result, the Colombian D-scores are much more precise than the Dutch.

```{r cohortsem, results = 'hide', fig.keep = 'all',  fig.cap = '(ref:cohortsem)', fig.align = 'center', echo = FALSE}
sem_daz_c <- sem_daz %>% 
  mutate(agecat = cut(agemos, breaks = 0:max(agemos, na.rm=TRUE)), 
         agenum = as.numeric(agecat))%>%
  group_by(cohort) %>% summarize ("n Q1(0.25)" = quantile(n, probs = 0.25, na.rm=TRUE), 
                                  "test length (median)" = median(n, na.rm = TRUE), 
                                  "n Q3(0.75)" = quantile(n, probs = 0.75, na.rm=TRUE), 
                                  "p Q1(0.25)" = round(quantile(p, probs = 0.25, na.rm=TRUE),2), 
                                  "pass probability (median)" = round(median(p, na.rm=TRUE),2),
                                  "p Q3(0.75)" = round(quantile(p, probs = 0.75, na.rm=TRUE),2),
                                  daz = mean(daz, na.rm = TRUE),
                                  mean_a = mean(a, na.rm=TRUE), #voor omzetting naar daz
                                  mean_d = mean(d, na.rm = TRUE),
                                  var_betw = var(d, na.rm = TRUE),
                                  var_with = sum(sem^2, na.rm = TRUE),
                                  n =  sum(!is.na(sem))
  ) %>% ungroup() %>%
  mutate(sem_pool = sqrt((var_with + var_betw)/ (n-1)), 
         low_d = mean_d - sem_pool,
         high_d = mean_d + sem_pool,
         mean_daz = dscore::daz(mean_d, x = mean_a),
         low_daz = dscore::daz(low_d, x = mean_a),
         high_daz = dscore::daz(high_d, x = mean_a)) %>%
  arrange(sem_pool)

  ggplot(data = sem_daz_c, aes(reorder(cohort, sem_pool), sem_pool)) +
  geom_col() + theme(axis.text.x = element_text(angle = 60, hjust = 1))+
    xlab("")+ ylab("Cohort sem")
  
  ## attach main instrument to cohort and see if that relates to sem? Or study kind? Something like that?
 
```

(ref:cohortsem) Cohort Standard Error of Measurement (*sem*).


```{r npsem, echo = FALSE}
kable(sem_daz_c[,c(1,3,6)], 
      col.names = c("Cohort", "Test length", "Pass probability"),
      caption = "Test length and probability to pass the items per cohort",
      booktabs = TRUE)
```

 

The ordering of studies depends on test length and item information. Table \@ref(tab:npsem) shows the median number of items per child (test length) and the probability to pass the item. The Ethiopian cohort `GCDG-ETH` administered 39 milestones with a median probability of 0.66. In contrast, the South Africa study `GCDG-ZAF` measures 12 items which were all very easy for the sample at hand (median probability of 1.0). One may thus well explain the extremes by test length and item information.

In general, the design of the study has a significant impact on the precision of the measurement. [Our ongoing work](https://stefvanbuuren.name/dbook3/) addresses the question how one may construct a measurement instrument that will be optimally precise given the goals of the research.

## Domain coverage {#sec:domains}

The D-score is a one-number summary of early child development. Traditional instruments distinguish domains (like motor, communication, language and cognitive development) and some provide ways to calculate a total score. The D-score, on the other hand, is based on the notion that child development is a unidimensional latent construct and hence does not provide domain scores. And thus, the question is how the D-score represents domains.

This section explores the following two questions:

-   Can we break down the D-score by domain contribution, and if so, can we evaluate whether the D-score fairly represents all domains?
-   Can we calculate domain-specific D-scores?

### Domain coverage of the scale

For many items in the D-score model, we had expert information available as to which domain the item belongs. For each item, we calculated the proportion of times the experts assigned it to one of five domains: Fine Motor, Gross Motor, Expressive, Receptive, Cognitive. We then calculated the distribution of domain by age.

```{r domaincov, results = 'hide', fig.keep = 'all', fig.cap = '(ref:domaincov)', echo = FALSE, fig.width=11}
info_data <-
      dinstrument::info_d_item(
        itembank = model_lean$itembank,
        delta = "tau",
        alpha = NULL,
        long = TRUE,
        beta_range = 0:80
      )

 #deal with missings in votes by then setting to instrument domain for 100%
 domaintable <- ddomain::get_domaintable("gcdg") %>%
         mutate(Fine.Motor = ifelse(is.na(Fine.Motor) & domain == "Fine Motor", 1, Fine.Motor),
          Fine.Motor = ifelse(is.na(Fine.Motor) & domain != "Fine Motor", 0, Fine.Motor),
          Gross.Motor = ifelse(is.na(Gross.Motor) & domain == "Gross Motor", 1, Gross.Motor),
          Gross.Motor = ifelse(is.na(Gross.Motor) & domain != "Gross Motor", 0, Gross.Motor), 
          Expressive = ifelse(is.na(Expressive) & domain == "Expressive", 1, Expressive),
          Expressive = ifelse(is.na(Expressive) & domain != "Expressive", 0, Expressive), 
          Receptive = ifelse(is.na(Receptive) & domain == "Receptive", 1, Receptive),
          Receptive = ifelse(is.na(Receptive) & domain != "Receptive", 0, Receptive), 
          Cognitive = ifelse(is.na(Cognitive) & domain == "Cognitive", 1, Cognitive),
          Cognitive = ifelse(is.na(Cognitive) & domain != "Cognitive", 0, Cognitive), 
          Adaptive = ifelse(is.na(Adaptive) & domain == "Adaptive", 1, Adaptive),
          Adaptive = ifelse(is.na(Adaptive) & domain != "Adaptive", 0, Adaptive))

 info_wby_domain <- info_data %>% left_join(domaintable) %>%
        mutate(
          gm_info = .data$Gross.Motor * .data$info,
          fm_info = .data$Fine.Motor * .data$info,
          exp_info = .data$Expressive * .data$info,
          rec_info = .data$Receptive * .data$info,
          cog_info = .data$Cognitive * .data$info,
          adp_info = .data$Adaptive * .data$info) %>%
        group_by(ability) %>%
        summarise(
          "Gross Motor" = sum(.data$gm_info, na.rm = TRUE)/sum(.data$info, na.rm = TRUE) *100,
          "Fine Motor" = sum(.data$fm_info, na.rm = TRUE)/sum(.data$info, na.rm = TRUE) *100,
          "Expressive" = sum(.data$exp_info, na.rm = TRUE)/sum(.data$info, na.rm = TRUE) *100,
          "Receptive" = sum(.data$rec_info, na.rm = TRUE)/sum(.data$info, na.rm = TRUE) *100,
          "Cognitive" = sum(.data$cog_info, na.rm = TRUE)/sum(.data$info, na.rm = TRUE) *100,
          "Adaptive" = sum(.data$adp_info, na.rm=TRUE)/sum(.data$info, na.rm = TRUE) *100,
          missing = (sum(.data$info) - sum(.data$gm_info, na.rm = TRUE) -
                       sum(.data$fm_info, na.rm = TRUE) - sum(.data$cog_info, na.rm = TRUE) -
                       sum(.data$exp_info, na.rm = TRUE) - sum(.data$rec_info, na.rm = TRUE) - sum(.data$adp_info, na.rm=TRUE) ) /sum(.data$info, na.rm = TRUE) *100
        ) %>%
        gather(key = "domain",
               value = "info",
               "Gross Motor",
               "Fine Motor",
               "Receptive",
               "Expressive",
               "Cognitive",
               "Adaptive",
               missing) %>%
        mutate(domain = ifelse(.data$domain =="missing",  NA, .data$domain))

 
    ggplot(data = info_wby_domain, aes(x = ability, y = info, fill = domain)) +
      geom_bar(stat = "identity", width = 1) +
      ylab("% of information") +
      xlab("Ability (D-score)")+
      scale_color_manual(values = dmodel::get_color_domain("gcdg"),
                         na.value = "grey")

  

```

(ref:domaincov) Domain coverage of the D-score scale.

Figure \@ref(fig:domaincov) shows the domain composition of the D-score across different levels of ability. Note that we miss domain information for a few items. The share of gross-motor is large in early development (e.g., between 15 and 30 months), and gradually tapers off at higher levels. Reversely, the percentage of cognition and language is relatively small before 30 months but rapidly rises as the child matures. These transitions in domain composition look both reasonable and valid.

### Domain-specific D-scores

Suppose we select a domain of interest and calculate the D-score only from items that substantially load onto that domain. We then get a domain-specific D-score. Items that relate to multiple domains contribute to multiple domain-specific D-scores.

```{r domaind, echo=FALSE, fig.cap='(ref:domaind)', fig.keep='all', cache=TRUE, results='hide', fig.width=11}
data_w <- dmetric::gcdg_lean[["itm"]] %>% spread(key = "item", value = "value") %>%
  left_join(gcdg_lean[["visit"]]) %>%
  mutate(age = agedays/365.25)

d_dom <- ddomain::d_domain(data = data_w, domain = c("Fine.Motor", "Gross.Motor", "Expressive", "Receptive", "Cognitive", "Adaptive"), items = gseddata::gcdg_items,domaintable = ddomain::get_domaintable(key = "gcdg"), vote_weight = 0)
d_all <- dscore(data = data_w, items = gseddata::gcdg_items, itembank = dscore::builtin_itembank, key = "gcdg")
d_dom1<- cbind(d_all, d_dom)

cortab <- cor(d_dom1[,c("daz" ,"daz_Fine.Motor", "daz_Gross.Motor", "daz_Cognitive", "daz_Receptive", "daz_Expressive")], use = "complete.obs")
row.names(cortab) <- c("DAZ", "Fine motor", "Gross Motor", "Cognitive", "Receptive", "Expressive")
colnames(cortab) <- c("DAZ", "Fine motor", "Gross Motor", "Cognitive", "Receptive", "Expressive")
d_dom_d <- d_dom %>%
  cbind(data_w[, c("cohort", "subjid", "agedays"), ]) %>%
  pivot_longer(
    cols = c(
      "d_Fine.Motor",
      "d_Gross.Motor",
      "d_Cognitive",
      "d_Receptive",
      "d_Expressive",
      "sem_Fine.Motor",
      "sem_Gross.Motor",
      "sem_Cognitive",
      "sem_Receptive",
      "sem_Expressive"
    ),
    values_to = "score",
    names_to = c("stat", "domain"),
    names_sep = "_"
  ) %>%
  select(c("subjid", "cohort", "agedays", "domain", "stat", "score")) %>%
  pivot_wider(
    id_cols = c("subjid", "agedays", "cohort", "domain"),
    names_from = "stat",
    values_from = "score",
    values_fn = list(score = first)
  ) %>%
  group_by(cohort, domain) %>%
  summarize (
    mean_a = mean((agedays / 365.25), na.rm = TRUE),
    #voor omzetting naar daz
    mean_d = mean(d, na.rm = TRUE),
    var_betw = var(d, na.rm = TRUE),
    var_with = sum(sem ^ 2, na.rm = TRUE),
    n =  sum(!is.na(sem))
  ) %>% ungroup() %>%
  mutate(
    sem_pool = sqrt((var_with + var_betw) / (n - 1)),
    low_d = mean_d - sem_pool,
    high_d = mean_d + sem_pool,
    mean_daz = dscore::daz(mean_d, x = mean_a),
    low_daz = dscore::daz(low_d, x = mean_a),
    high_daz = dscore::daz(high_d, x = mean_a)
  )

ggplot(d_dom_d, aes(
  # x = reorder(cohort, desc(cohort)),
  x = cohort,
  y = mean_daz,
  color = domain
)) +
  geom_point(size = 1, position = position_dodge(width = 0.5)) +
  geom_errorbar(
    aes(
      x = cohort,
      ymin = (low_daz),
      ymax = (high_daz),
      group = domain
    ),
    width = .1,
    position = position_dodge(width = 0.5)
  ) +
  # coord_flip()+
  ylab("Average domain-specific DAZ") +
  ylim(-4,4)+
  xlab("") +
  theme(
    legend.position = "top",
    legend.title = element_blank(),
    axis.text.x = element_text(angle = 90)
  )
```

(ref:domaind) Average domain-specific DAZ $\pm$ *sem* by cohort.

Figure \@ref(fig:domaind) displays the standardized domain-specific D-score (i.e. DAZ) per cohort. The DAZ strips out irrelevant age variation, and thus enhances comparability between cohorts. The error bars around the scores depict the *sem* interval. We observe some variation in domain-specific DAZ scores within cohorts. Still, these differences are relatively small and well within the margins of error. This analysis suggests that the D-score is an excellent overall summary of the domain-specific D-scores.

The D-score methodology assumes that child development is a unidimensional scale. As a consequence, the correlations between different domain-specific D-scores are extremely high ($r > 0.95$). It is more interesting to study the correlation between the DAZ equivalent of the domain-specific scores.

```{r domaincor, echo=FALSE, cache=TRUE}
knitr::kable(round(cortab, 2),
            caption = "Pearson correlation of the DAZ and five domain-specific DAZ scores")
```

 

Table \@ref(tab:domaincor) lists the Pearson correlation matrix of the DAZ and the five domain-specific DAZ scores. All correlations between the DAZ and the domain-specific scores are high, thus confirming the generic character of the D-score and DAZ. We find high inter-domain correlations for the cognitive-receptive, cognitive-fine motor and expressive-receptive pairs. The gross motor domain appears as somewhat distinct from the four other domains. Its position may be genuine, but could also be related to the smaller number of responses on gross motor milestones in the GCDG data.

```{r domaindex, echo=FALSE, fig.cap='(ref:domaindex)', fig.keep='all', results='hide', fig.width=11, fig.heiht = 3}

#calculate dscore per domain by using only items that are loading on the domain - items can load on multiple domains
#use vote_weight to indicate the minimum percentage of votes for the domain (ex. 0.5 at least half of the votes must be on the domain for that item to load on that domain)

data_w <- dmetric::gcdg_lean[["itm"]] %>% spread(key = "item", value = "value") %>%
  left_join(gcdg_lean[["visit"]]) %>%
  mutate(age = agedays/365.25)
dati <- data_w[9817,]

d_dom_ex <- d_domain(data = dati, domain = c("Fine.Motor", "Gross.Motor", "Expressive", "Receptive", "Cognitive", "Adaptive"), items = gseddata::gcdg_items,domaintable = ddomain::get_domaintable(key = "gcdg"), vote_weight = 0)


d_dom_ex_d <- d_dom_ex %>% select(c("a", "d_Fine.Motor", "d_Gross.Motor", "d_Cognitive", "d_Receptive", "d_Expressive")) %>% pivot_longer(cols = c("d_Fine.Motor", "d_Gross.Motor", "d_Cognitive", "d_Receptive", "d_Expressive"), names_to = "domain", values_to = "d") %>% mutate(domain = gsub("d_", "", .data$domain))

d_dom_ex_sem <- d_dom_ex %>% select(c("sem_Fine.Motor", "sem_Gross.Motor", "sem_Cognitive", "sem_Receptive", "sem_Expressive")) %>% pivot_longer(cols = c("sem_Fine.Motor", "sem_Gross.Motor", "sem_Cognitive", "sem_Receptive", "sem_Expressive"), names_to = "domain", values_to = "sem") %>% mutate(domain = gsub("sem_", "", .data$domain))

d_dom_ex_n <- d_dom_ex %>% select(c("n_Fine.Motor", "n_Gross.Motor", "n_Cognitive", "n_Receptive", "n_Expressive")) %>% pivot_longer(cols = c("n_Fine.Motor", "n_Gross.Motor", "n_Cognitive", "n_Receptive", "n_Expressive"), names_to = "domain", values_to = "n") %>% mutate(domain = gsub("n_", "", .data$domain))

d_dom_plot <- left_join(d_dom_ex_d, d_dom_ex_n, by = "domain")
d_dom_plot <- left_join(d_dom_plot, d_dom_ex_sem, by = "domain")

d_all <- dscore(data = dati, items = gseddata::gcdg_items, itembank = dscore::builtin_itembank, key = "gcdg")



ggplot(data = d_dom_plot, aes(x = domain, y = d, color = domain))+
  geom_point() + geom_errorbar(aes(x = domain, ymin = (d-sem), ymax = (d+sem)), width = .1)+
  geom_abline(intercept = d_all$d, slope = 0, col = "darkgrey")+
  geom_abline(intercept = (d_all$d-d_all$sem), slope = 0, lty=2, col = "grey")+
  geom_abline(intercept =(d_all$d+d_all$sem), slope = 0, lty = 2, col = "grey")+
  geom_bar(stat = "identity", aes(x = domain, y = n, fill = domain))+
  geom_abline(intercept = 5, slope = 0, col = "white")+

 ylim(0,80) +
  ylab("Number of items                                                                                                      D-score") +
  xlab("")+
  theme(legend.position = "none")+
  coord_flip()


```

(ref:domaindex) Domain-specific D-scores for a 3 year old boy.

Figure \@ref(fig:domaindex) displays individual scores for a 3 year old boy. The filled bars indicate the number of available items per domain. The vertical white line that crosses the horizontal axis at value 5 indicates a threshold for a minimum number of items needed for a D-score. Note that the number of items for Gross Motor in this example is meagre (only three items). The grey vertical line indicates the value of the overall D-score (68.55$D$). The nearby dashed lines are located at one *sem* (0.53$D$) distance. The coloured points are the domain-specific D-scores with the *sem* around in error bars. The plot visualises that the boys' scores on language domains (i.e. Expressive and Receptive) are low as compared to the motor and cognitive domains. A systematic discrepancy between various domain-specific scores might be an early warning sign for developmental delay.
