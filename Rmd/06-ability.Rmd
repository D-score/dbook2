```{r ch6libs, include=FALSE}
library(ggplot2)
library(dmetric)
library(gseddata)
library(kableExtra)
library(ddomain)
library(dplyr)
library(tidyr)
library(dscore)
```
# Comparing ability {#ch:ability}

> Author: Iris Eekhout

Once we identified a satisfactory D-score model, we may calculate the D-score for children from different cohorts and compare their values. This chapter highlights various techniques and issues for comparing D-score distributions between studies. We will address the following topics:

* Comparing child development across studies (\@ref(sec:dscores))
* Precision of the D-score (\@ref(sec:sem))
* Domain coverage (\@ref(sec:domains))

## Comparing child development across studies {#sec:dscores}

```{r dscoredist, echo=FALSE, out.width="760px", fig.cap = '(ref:dscoredist)'}
knitr::include_url("https://iriseekhout.github.io/dbook2tools/gcdgdscores/#display=by_cohort&nrow=1&ncol=1&arr=row&pg=6&labels=cohort&sort=cohort;asc&filter=&sidebar=&fv=", 
  height = "800px")
```
(ref:dscoredist) D-score distributions by study. Click [ZOOM](https://iriseekhout.github.io/dbook2tools/gcdgdscores/#display=by_cohort&nrow=1&ncol=1&arr=row&pg=6&labels=cohort&sort=cohort;asc&filter=&sidebar=&fv=) to enlarge the image.

Figure \@ref(fig:dscoredist) shows the scatterplot of the D-score by age separately for each cohort. Remember from section \@ref(sec:gcdgoverview) that each study selected its own set of instruments to collect the data. The scatterplots demonstrate a significant advance made possible by the D-score: We can plot the developmental scores of children from __different__ cohorts, with __different__ ages, using __different__ instruments, on the __same__ vertical axis. 

The five blue lines guide the eye. These lines indicate the locations of the -2SD, -1SD, 0SD, +1SD and +2SD quantiles at each age in the combined data.  [Section I:5.4](https://stefvanbuuren.name/dbook1/sec-reference.html) motivates the idea and provides some technical details. We'll come back to these lines in section \@ref(sec:references).

By and large, the data in every study follow the blue lines. Perhaps the most obvious exception is the `GCDG-JAM-STUNTED` cohort, where older children somewhat exceed the D-score range. It is unknown whether this is real, or due to a weak calibration of the instrument. 

Replacing the D-score by the DAZ emphasises any differences both within and between studies.

[Include DAZ plot here]

## Precision of the D-score {#sec:sem}

The [EAP algorithm](https://stefvanbuuren.name/dbook1/sec-dscoreestimation.html#eap-algorithm-numerical-example) estimates the D-score from a set of PASS/FAIL scores. The standard deviation of the posterior distribution (or *sem*: standard error of measurement) quantifies the imprecision of the D-score estimate. The *sem* is inversely related to the number of items. Thus, when we administer more milestones, the sem of the D-score drops.

```{r semforn, results = 'hide', fig.keep = 'all', fig.cap = '(ref:semforn)', fig.align='center', echo = FALSE, fig.width=6}
ggplot(data = dmetric::model_lean$dscore )+
  geom_smooth(aes(x=n, y=sem), formula = y ~ splines::bs(x, 4), se = FALSE, color = mice::mdc(2))+
  xlab("Number of items administered") +
  ylab("Standard error of measurement")
```
(ref:semforn) Standard error of measurement (*sem*) as a function of the number of items.

Figure \@ref(fig:semforn) shows that the *sem* drops off rapidly when the number of
items is low and stabilises after about 35 items. Apart from test length, the precision of the D-score also depends on item information (c.f. section \@ref(sec:iteminformation)). Administering items that are too easy, or too difficult, does not improve precision. The figure suggests that - in practice - a single D-score cannot be more precise than 0.5 D-score units.

```{r semfora, echo=FALSE, fig.cap='(ref:semfora)', fig.keep='all', results='hide', fig.height=7, fig.width=7, fig.align='center'}
# voor individuele metingen
sem_daz <- dmetric::model_lean$dscore %>%
  mutate(agemos = a *12,
         low_d = d - sem,
         high_d = d +sem, 
         low_daz = dscore::daz(low_d, x = a),
         high_daz = dscore::daz(high_d, x = a))


## of dit berekenen via de pooled sem per age group en daarna pas naar daz omzetten
#pooled sem = srqt(sum(sem^2)/(length(sem)-1))
#alleen gaat het dan mis dat de gemiddelde daz soms buiten het inderval komt (in begin maanden vooral)
#>># proberen door between variantie (var(d)) toe te voegen aan de pooling van de varianties
sem_daz_a <- sem_daz %>% 
  mutate(agecat = cut(agemos, breaks = 0:max(agemos, na.rm=TRUE)), 
         agenum = as.numeric(agecat))%>%
  group_by(agenum) %>% 
  summarize (daz = mean(daz, na.rm = TRUE),
             mean_a = mean(a, na.rm=TRUE), #voor omzetting naar daz
             mean_d = mean(d, na.rm = TRUE),
             var_betw = var(d, na.rm = TRUE),
             var_with = sum(sem^2, na.rm = TRUE),
             n =  sum(!is.na(sem))
             ) %>% ungroup() %>%
  mutate(sem_pool = sqrt((var_with + var_betw)/ (n-1)), 
         low_d = mean_d - sem_pool,
         high_d = mean_d + sem_pool,
         mean_daz = dscore::daz(mean_d, x = mean_a),
         low_daz = dscore::daz(low_d, x = mean_a),
         high_daz = dscore::daz(high_d, x = mean_a))

#ggplot(data = sem_daz_a )+
#  geom_point(aes(x=agenum, y=daz)) +
#  geom_errorbar(aes(x = agenum, ymin=low_daz, ymax=high_daz), width=.1)+
#  xlab("age(months)")+
#  ylim(c(-2,2))

ggplot(data = sem_daz_a )+
  geom_point(aes(x=agenum, y=mean_daz)) +
  geom_errorbar(aes(x = agenum, ymin=low_daz, ymax=high_daz), width=.1)+
  xlab("Age (months)") + ylab("DAZ") +
  ylim(c(-2,2))

#ggplot(data = sem_daz_a )+
#  geom_point(aes(x=agenum, y=mean_d)) +
#  geom_errorbar(aes(x = agenum, ymin=low_d, ymax=high_d), width=.1)+
#  xlab("age(months)") + ylab("D-score")


```
(ref:semfora) Mean DAZ $\pm$ *sem* as a function of age.

One may wonder whether the *sem* depends on age. Figure \@ref(fig:semfora) suggests that this is not the case. The average DAZ is close to zero everywhere, as expected. The interval DAZ $\pm$ *sem* will cover the true, but unknown, DAZ in about 68% of the cases. While the interval varies somewhat across ages, there is no systematic age trend. 

```{r dscoresems, echo=FALSE, out.width="760px", fig.cap = '(ref:dscoresems)', fig.align='center'}
#n items per child Netherlands 1 cohort = 8.5
#ids <- gcdg_lean$visit$subjid[which(gcdg_lean$visit$cohort=="GCDG-NLD-SMOCC")]
#itm <- gcdg_lean$itm[which(gcdg_lean$itm$subjid %in% ids),]
#itmn <- itm %>% group_by(subjid, agedays) %>% summarize(n=n())
#summary(itmn)
#p per child on average for Netherlands 1 cohort = 0.8 (median)
#summary(model_lean$dscore$p[which(model_lean$dscore$cohort == "GCDG-NLD-SMOCC")])

#n items per child Colombia cohort = 46
#ids <- gcdg_lean$visit$subjid[which(gcdg_lean$visit$cohort=="GCDG-COL-LT45M")]
#itm <- gcdg_lean$itm[which(gcdg_lean$itm$subjid %in% ids),]
#itmn <- itm %>% group_by(subjid, agedays) %>% summarize(n=n())
#summary(itmn)
#p per child on average for Colombia 1 cohort = 0.63 (median)
#summary(model_lean$dscore$p[which(model_lean$dscore$cohort == "GCDG-COL-LT45M")])
#knitr::include_app("https://tnochildhealthstatistics.shinyapps.io/GCDG_sem/", 
#  height = "700px")
knitr::include_url("https://iriseekhout.github.io/dbook2tools/gcdgsem/#display=by_cohort&nrow=1&ncol=1&arr=row&pg=6&labels=cohort&sort=cohort;asc&filter=&sidebar=&fv=",
                   height = "800px")
```
(ref:dscoresems) The standard error of measurement ($sem$) around the age-standardized D-scores (DAZ) per cohort. Click [ZOOM](https://iriseekhout.github.io/dbook2tools/gcdgsem/#display=by_cohort&nrow=1&ncol=1&arr=row&pg=6&labels=cohort&sort=cohort;asc&filter=&sidebar=&fv=) to enlarge the display.

Does precision vary with studies? The answer is yes. Figure \@ref(fig:dscoresems) plots the same information as before but now broken down according to cohort. Individual data points are added to give a feel for the design. The Colombia cohort `GCDG-COL-LT45M` administered the Bayley-III, where each child answered on average 45 items, so the *sem* is small. In contrast, the Dutch cohort GCDG-NLD-SMOCC collected data on a screener consisting of about ten relatively easy milestones, so the *sem* is relatively large. As a result, the Colombian D-scores are much more precise than the Dutch.

<!-- The $sem$ for an entire cohort or sample can be obtained by pooling the -->
<!-- individual $sem_i$ using general rule for pooling variances. Accordingly, the -->
<!-- $sem$ for a sample is obtained by combining the within variance -->
<!-- $\sum{sem_{i}^2}$ and the between variance $\sigma_d$ as in equation -->
<!-- \@ref(eq:poolsem) -->

<!-- \begin{equation} -->
<!-- sem = \sqrt{\frac{\sum{sem_{i}^2} + \sigma_d }{N-1}} (\#eq:poolsem) -->
<!-- \end{equation} -->

```{r cohortsem, results = 'hide', fig.keep = 'all',  fig.cap = '(ref:cohortsem)', fig.align = 'center', echo = FALSE}
sem_daz_c <- sem_daz %>% 
  mutate(agecat = cut(agemos, breaks = 0:max(agemos, na.rm=TRUE)), 
         agenum = as.numeric(agecat))%>%
  group_by(cohort) %>% summarize ("n Q1(0.25)" = quantile(n, probs = 0.25, na.rm=TRUE), 
                                  "test length (median)" = median(n, na.rm = TRUE), 
                                  "n Q3(0.75)" = quantile(n, probs = 0.75, na.rm=TRUE), 
                                  "p Q1(0.25)" = round(quantile(p, probs = 0.25, na.rm=TRUE),2), 
                                  "pass probability (median)" = round(median(p, na.rm=TRUE),2),
                                  "p Q3(0.75)" = round(quantile(p, probs = 0.75, na.rm=TRUE),2),
                                  daz = mean(daz, na.rm = TRUE),
                                  mean_a = mean(a, na.rm=TRUE), #voor omzetting naar daz
                                  mean_d = mean(d, na.rm = TRUE),
                                  var_betw = var(d, na.rm = TRUE),
                                  var_with = sum(sem^2, na.rm = TRUE),
                                  n =  sum(!is.na(sem))
  ) %>% ungroup() %>%
  mutate(sem_pool = sqrt((var_with + var_betw)/ (n-1)), 
         low_d = mean_d - sem_pool,
         high_d = mean_d + sem_pool,
         mean_daz = dscore::daz(mean_d, x = mean_a),
         low_daz = dscore::daz(low_d, x = mean_a),
         high_daz = dscore::daz(high_d, x = mean_a)) %>%
  arrange(sem_pool)

  ggplot(data = sem_daz_c, aes(reorder(cohort, sem_pool), sem_pool)) +
  geom_col() + theme(axis.text.x = element_text(angle = 60, hjust = 1))+
    xlab("")+ ylab("Cohort sem")
  
  ## attach main instrument to cohort and see if that relates to sem? Or study kind? Something like that?
 
```
(ref:cohortsem) Cohort Standard Error of Measurement (*sem*).

Figure \@ref(fig:cohortsem) summarises the $sem$ over the members of each cohort. The Ethiopia study GCDG-ETH is the most precise. In contrast, the D-score values in studies from South Africa, Ecuador and The Netherlands have sizeable measurement error. 

```{r npsem, echo = FALSE}
kable(sem_daz_c[,c(1,3,6)], 
      col.names = c("Cohort", "Test length", "Pass probability"),
      caption = "Test length and probability to pass the items per cohort",
      bootabs = TRUE)

```
&nbsp;

The ordering of studies depends on test length and item information. Table \@ref(tab:npsem) shows the median number of items per child (test length) and the probability to pass the item. The Ethiopian cohort `GCDG-ETH` administered 39 milestones with a median probability of 0.66. In contrast, the South Africa study `GCDG-ZAF` measures 12 items which were all very easy for the sample at hand (median probability of 1.0). One may thus well explain the extremes by test length and item information.

In general, the design of the study has a significant impact on the precision of the measurement. [Booklet III](https://stefvanbuuren.name/dbook3/) addresses the question how one may construct a measurement instrument that will be optimally precise given the goals of the research. 

## Domain coverage {#sec:domains}
 
The D-score is a one number score that measures early child development. To
evaluate the content validity of the D-score we can make sure that all
developmental domains are fairly represented. We distinguish five domains for
child development: Fine Motor, Gross Motor, Expressive, Receptive, Cognitive. 

### Domain coverage of the scale

The items in the D-score model can be linked to one or more domains and the
cumulative item information to the D-score for each domain can be evaluated.
In Figure \@ref(fig:domaincov), the coverage of the domains for the D-score is
displayed. This shows that at lower levels of the D-score, gross motor development
is more dominant and that at higher levels of the D-score the cognitive and
language domains increase in importance.


```{r domaincov, results = 'hide', fig.keep = 'all', fig.cap = '(ref:domaincov)', echo = FALSE, fig.width=11}
info_data <-
      dinstrument::info_d_item(
        itembank = model_lean$itembank,
        delta = "tau",
        alpha = NULL,
        long = TRUE,
        beta_range = 0:80
      )

 #deal with missings in votes by then setting to instrument domain for 100%
 domaintable <- ddomain::get_domaintable("gcdg") %>%
         mutate(Fine.Motor = ifelse(is.na(Fine.Motor) & domain == "Fine Motor", 1, Fine.Motor),
          Fine.Motor = ifelse(is.na(Fine.Motor) & domain != "Fine Motor", 0, Fine.Motor),
          Gross.Motor = ifelse(is.na(Gross.Motor) & domain == "Gross Motor", 1, Gross.Motor),
          Gross.Motor = ifelse(is.na(Gross.Motor) & domain != "Gross Motor", 0, Gross.Motor), 
          Expressive = ifelse(is.na(Expressive) & domain == "Expressive", 1, Expressive),
          Expressive = ifelse(is.na(Expressive) & domain != "Expressive", 0, Expressive), 
          Receptive = ifelse(is.na(Receptive) & domain == "Receptive", 1, Receptive),
          Receptive = ifelse(is.na(Receptive) & domain != "Receptive", 0, Receptive), 
          Cognitive = ifelse(is.na(Cognitive) & domain == "Cognitive", 1, Cognitive),
          Cognitive = ifelse(is.na(Cognitive) & domain != "Cognitive", 0, Cognitive), 
          Adaptive = ifelse(is.na(Adaptive) & domain == "Adaptive", 1, Adaptive),
          Adaptive = ifelse(is.na(Adaptive) & domain != "Adaptive", 0, Adaptive))

 info_wby_domain <- info_data %>% left_join(domaintable) %>%
        mutate(
          gm_info = .data$Gross.Motor * .data$info,
          fm_info = .data$Fine.Motor * .data$info,
          exp_info = .data$Expressive * .data$info,
          rec_info = .data$Receptive * .data$info,
          cog_info = .data$Cognitive * .data$info,
          adp_info = .data$Adaptive * .data$info) %>%
        group_by(ability) %>%
        summarise(
          "Gross Motor" = sum(.data$gm_info, na.rm = TRUE)/sum(.data$info, na.rm = TRUE) *100,
          "Fine Motor" = sum(.data$fm_info, na.rm = TRUE)/sum(.data$info, na.rm = TRUE) *100,
          "Expressive" = sum(.data$exp_info, na.rm = TRUE)/sum(.data$info, na.rm = TRUE) *100,
          "Receptive" = sum(.data$rec_info, na.rm = TRUE)/sum(.data$info, na.rm = TRUE) *100,
          "Cognitive" = sum(.data$cog_info, na.rm = TRUE)/sum(.data$info, na.rm = TRUE) *100,
          "Adaptive" = sum(.data$adp_info, na.rm=TRUE)/sum(.data$info, na.rm = TRUE) *100,
          missing = (sum(.data$info) - sum(.data$gm_info, na.rm = TRUE) -
                       sum(.data$fm_info, na.rm = TRUE) - sum(.data$cog_info, na.rm = TRUE) -
                       sum(.data$exp_info, na.rm = TRUE) - sum(.data$rec_info, na.rm = TRUE) - sum(.data$adp_info, na.rm=TRUE) ) /sum(.data$info, na.rm = TRUE) *100
        ) %>%
        gather(key = "domain",
               value = "info",
               "Gross Motor",
               "Fine Motor",
               "Receptive",
               "Expressive",
               "Cognitive",
               "Adaptive",
               missing) %>%
        mutate(domain = ifelse(.data$domain =="missing",  NA, .data$domain))

 
    ggplot(data = info_wby_domain, aes(x = ability, y = info, fill = domain)) +
      geom_bar(stat = "identity", width = 1) +
      ylab("% of information") +
      xlab("Ability (D-score)")+
      scale_color_manual(values = dmodel::get_color_domain("gcdg"),
                         na.value = "grey")

  

```
(ref:domaincov) Domain coverage of the D-score scale.

Note that for some items the domain allocation is missing.  

### Domain D-scores

It is possible to calculate a D-score that is more representative for a
specific domain using the current D-score model. We can use only the items
that load to the domain in question to calculate the D-score for that specific
domain. Since items may relate to multiple domain, an item can contribute to
multiple domain specific D-scores. As the D-score methodology is developed
to measure a single construct for development, the domain D-scores correlate
highly ($r > 0.95$). However, these scores can potentially inform on the cohort
level (Figure \@ref(fig:domaind)) or the individual level (see Figure
\@ref(fig:domaindex)).

In Figure \@ref(fig:domaind), the standardized domain D-score (i.e. DAZ) are displayed for each cohort. The DAZ unit was used to enable comparibility. The error bars around the scores depict the $sem$ interval. The mean domain specific DAZ scores differ within cohorts, however the $sem$ intervals always overlap.

<!--- the correlations between the daz scores are much lower. How should we interpet that? I think it may also be due to differences in precision of the maesurement. The correlations to the daz based on all items may also be informative on that. Gross motor has low correlations to all scales, but that may also be due to nr of items. --->

```{r domaind, echo=FALSE, fig.cap='(ref:domaind)', fig.keep='all', cache=TRUE, results='hide', fig.width=11}
data_w <- dmetric::gcdg_lean[["itm"]] %>% spread(key = "item", value = "value") %>%
  left_join(gcdg_lean[["visit"]]) %>%
  mutate(age = agedays/365.25)

d_dom <- ddomain::d_domain(data = data_w, domain = c("Fine.Motor", "Gross.Motor", "Expressive", "Receptive", "Cognitive", "Adaptive"), items = gseddata::gcdg_items,domaintable = ddomain::get_domaintable(key = "gcdg"), vote_weight = 0)
d_all <- dscore(data = data_w, items = gseddata::gcdg_items, itembank = dscore::builtin_itembank, key = "gcdg")
d_dom1<- cbind(d_all, d_dom)

cor(d_dom1[,c("daz" ,"daz_Fine.Motor", "daz_Gross.Motor", "daz_Cognitive", "daz_Receptive", "daz_Expressive")], use = "complete.obs")

d_dom_d <- d_dom %>%
  cbind(data_w[, c("cohort", "subjid", "agedays"), ]) %>%
  pivot_longer(
    cols = c(
      "d_Fine.Motor",
      "d_Gross.Motor",
      "d_Cognitive",
      "d_Receptive",
      "d_Expressive",
      "sem_Fine.Motor",
      "sem_Gross.Motor",
      "sem_Cognitive",
      "sem_Receptive",
      "sem_Expressive"
    ),
    values_to = "score",
    names_to = c("stat", "domain"),
    names_sep = "_"
  ) %>%
  select(c("subjid", "cohort", "agedays", "domain", "stat", "score")) %>%
  pivot_wider(
    id_cols = c("subjid", "agedays", "cohort", "domain"),
    names_from = "stat",
    values_from = "score",
    values_fn = list(score = first)
  ) %>%
  group_by(cohort, domain) %>%
  summarize (
    mean_a = mean((agedays / 365.25), na.rm = TRUE),
    #voor omzetting naar daz
    mean_d = mean(d, na.rm = TRUE),
    var_betw = var(d, na.rm = TRUE),
    var_with = sum(sem ^ 2, na.rm = TRUE),
    n =  sum(!is.na(sem))
  ) %>% ungroup() %>%
  mutate(
    sem_pool = sqrt((var_with + var_betw) / (n - 1)),
    low_d = mean_d - sem_pool,
    high_d = mean_d + sem_pool,
    mean_daz = dscore::daz(mean_d, x = mean_a),
    low_daz = dscore::daz(low_d, x = mean_a),
    high_daz = dscore::daz(high_d, x = mean_a)
  )




ggplot(d_dom_d, aes(
  x = reorder(cohort, desc(cohort)),
  y = mean_daz,
  color = domain
)) +
  geom_point(size = 1, position = position_dodge(width = 0.5)) +
  geom_errorbar(
    aes(
      x = cohort,
      ymin = (low_daz),
      ymax = (high_daz),
      group = domain
    ),
    width = .1,
    position = position_dodge(width = 0.5)
  ) +
  # coord_flip()+
  ylab("Average domain specific DAZ") +
  ylim(-4,4)+
  xlab("") +
  theme(
    legend.position = "top",
    legend.title = element_blank(),
    axis.text.x = element_text(angle = 90)
  )

```
(ref:domaind) Domain DAZ per cohort. 

In Figure \@ref(fig:domaindex) example scores are displayed for a 3 year old boy
from the Chili 2 (`GCDG-CHL-2`) cohort. The filled bars display the available items per domain. Note
that the number of items for Gross Motor is very low (only 3 items). The white
overlayed line at 5 items, indicates the bare minimum for a D-score. The grey vertical line displays the overall
D-score (38.55$D$) with the $sem$ (0.53) around as the dashed lines. The colored points are the domain D-scores with the $sem$ around in error bars. This plot shows that for the language domains (i.e. Expressive and Receptive), this boy scores relatively low as compared to the motor and cognitive domains. 



```{r domaindex, echo=FALSE, fig.cap='(ref:domaindex)', fig.keep='all', results='hide', fig.width=11, fig.heiht = 4}

#calculate dscore per domain by using only items that are loading on the domain - items can load on multiple domains
#use vote_weight to indicate the minimum percentage of votes for the domain (ex. 0.5 at least half of the votes must be on the domain for that item to load on that domain)

data_w <- dmetric::gcdg_lean[["itm"]] %>% spread(key = "item", value = "value") %>%
  left_join(gcdg_lean[["visit"]]) %>%
  mutate(age = agedays/365.25)
dati <- data_w[9817,]

d_dom_ex <- d_domain(data = dati, domain = c("Fine.Motor", "Gross.Motor", "Expressive", "Receptive", "Cognitive", "Adaptive"), items = gseddata::gcdg_items,domaintable = ddomain::get_domaintable(key = "gcdg"), vote_weight = 0)


d_dom_ex_d <- d_dom_ex %>% select(c("a", "d_Fine.Motor", "d_Gross.Motor", "d_Cognitive", "d_Receptive", "d_Expressive")) %>% pivot_longer(cols = c("d_Fine.Motor", "d_Gross.Motor", "d_Cognitive", "d_Receptive", "d_Expressive"), names_to = "domain", values_to = "d") %>% mutate(domain = gsub("d_", "", .data$domain))

d_dom_ex_sem <- d_dom_ex %>% select(c("sem_Fine.Motor", "sem_Gross.Motor", "sem_Cognitive", "sem_Receptive", "sem_Expressive")) %>% pivot_longer(cols = c("sem_Fine.Motor", "sem_Gross.Motor", "sem_Cognitive", "sem_Receptive", "sem_Expressive"), names_to = "domain", values_to = "sem") %>% mutate(domain = gsub("sem_", "", .data$domain))

d_dom_ex_n <- d_dom_ex %>% select(c("n_Fine.Motor", "n_Gross.Motor", "n_Cognitive", "n_Receptive", "n_Expressive")) %>% pivot_longer(cols = c("n_Fine.Motor", "n_Gross.Motor", "n_Cognitive", "n_Receptive", "n_Expressive"), names_to = "domain", values_to = "n") %>% mutate(domain = gsub("n_", "", .data$domain))

d_dom_plot <- left_join(d_dom_ex_d, d_dom_ex_n, by = "domain")
d_dom_plot <- left_join(d_dom_plot, d_dom_ex_sem, by = "domain")

d_all <- dscore(data = dati, items = gseddata::gcdg_items, itembank = dscore::builtin_itembank, key = "gcdg")



ggplot(data = d_dom_plot, aes(x = domain, y = d, color = domain))+
  geom_point() + geom_errorbar(aes(x = domain, ymin = (d-sem), ymax = (d+sem)), width = .1)+
  geom_abline(intercept = d_all$d, slope = 0, col = "darkgrey")+
  geom_abline(intercept = (d_all$d-d_all$sem), slope = 0, lty=2, col = "grey")+
  geom_abline(intercept =(d_all$d+d_all$sem), slope = 0, lty = 2, col = "grey")+
  geom_bar(stat = "identity", aes(x = domain, y = n, fill = domain))+
  geom_abline(intercept = 5, slope = 0, col = "white")+

 ylim(0,80) +
  ylab("number of items                                                                                                      D-score") +
  xlab("")+
  theme(legend.position = "none")+
  coord_flip()


```
(ref:domaindex) Domain D-scores for a 3 year old boy from the Chile 2 cohort. 
