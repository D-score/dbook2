```{r ch3libs, include=FALSE}
library("dmodel")
library("dmetric")
library("gseddata")
library(dplyr)
library(kableExtra)
library(knitr)
```



<!-- NOTE: We may need to reorganise a little. Move "Challenge of comparability" and "Bridging instruments" to before chapter 2. Then this chapter can concentrate on the identification and assessment of similar items 
Jan2SvB: Now rewritten 3.1 to connectedness -->

# Comparability {#ch:comparability}

This chapter describes challenges and methodologies to harmonize child development measurements obtained by different instruments:

* Are instruments connected? (\@ref(sec:challenge))
* Bridging instruments by mapping items (\@ref(sec:mapping))
* Overview of promising item mappings (\@ref(sec:viewmapping))

## Are instruments connected? {#sec:challenge}

The ultimate goal is to compare child development across populations and cultures. A complication is that measurements are made by different instruments. To do deal with this issue, we harmonize the data included in the GCDG cohorts. In particular, we process the milestone responses such that the following requirements hold:

* Every milestone in an instrument has a unique name and a descriptive label;
* Every milestone occupies one column in the dataset;
* Item scores are (re)coded as: 1 = PASS; 0 = FAIL;
* Items not administered or not answered are a missing value;
* Every row in the dataset corresponds to a unique cohort-child-age combination.

Cohorts and milestones need to be *connected*. There are several ways to connect cohorts:

* Two cohorts are directly connected if they use the same instrument;
* Two cohorts are indirectly connected if both connect to a third cohort that connects them.

Likewise, instruments can be connected:

* Two instruments are directly connected if the same cohort measures both;
* Two instruments are indirectly connected if both connect to a third instrument that connects them.


```{r linkage, echo = FALSE}

pattern <- matrix("", nrow = 16, ncol = 15)
pattern[8, 1] <- "X"
pattern[9, 2] <- "X"
pattern[c(3, 5, 8), 3] <- "X"
pattern[4, 4] <- "X"
pattern[c(1, 16), 5] <- "X"
pattern[c(6, 7, 8, 10), 6] <- "X"
pattern[c(14, 15), 7] <- "X"
pattern[c(2, 8), 8] <- "X"
pattern[c(11, 12, 16), 9] <- "X"
pattern[13, 10] <- "X"
pattern[13, 11] <- "X"
pattern[13, 12] <- "X"
pattern[16, 13] <- "X"
pattern[5, 14] <- "X"
pattern[16, 15] <- "X"
colnames(pattern) <- 
  c("aqi", "bar", "bat", "by1", "by2", "by3", "ddi", 
    "den", "gri", "mac", "peg", "sbi", "sgr", "tep", "vin")
df <- data.frame(
  pattern,
  row.names = 
    c("Bangladesh", "Brazil 1", "Brazil 2", "Chile 1", "Chile 2", 
    "China", "Colombia 1", "Colombia 2", "Ecuador", "Ethiopia",
    "Jamaica 1", "Jamaica 2", "Madagascar", "Netherlands1", 
    "Netherlands2", "South Africa")

)

knitr::kable(df, 
  caption = "Linkage pattern indicating combinations of cohorts and instruments.",
  booktabs = TRUE) %>%
  kableExtra::kable_styling() %>%
  kableExtra::scroll_box(width = "100%", height = "500px")
```
&nbsp;

An `X` in Table \@ref(tab:linkage) identifies which cohorts use which instruments. The linkage table shows that studies from China, Colombia and Ethiopia are directly connected (by `by3`). Brazil 1 indirectly connects to these studies through `den`. Some cohorts (e.g., Chile 1 and Ecuador) do not link to any other study. Likewise, we might say that `aqi`, `bat`, `by3` and `den` are directly connected. Note that no indirect connections exist to this instrument group.

Table \@ref(tab:linkage) is a somewhat simplified version of the linkage pattern. As we saw in section \@ref(sec:cohorts), there are substantial age differences between the cohorts. The linked [instrument linkage table](https://tnochildhealthstatistics.shinyapps.io/GCDG_instrument_linkage/) shows the counts of the number of registered scores per age group. What appears in Table \@ref(tab:linkage) as one test may actually comprise of two disjoint subsets, and hence some cohorts may not be connected after all.

Connectedness is a necessary - though not sufficient - requirement for parameter identification. If two cohorts are not connected, we cannot distinguish between the following two alternative explanations:

* Any differences between studies can be attributed to the ability of the children;
* Any differences between studies can be attributed to the difficulties of the instruments.

The data do not contain the necessary information to discriminate between these two explanations. Since many cohorts in Table \@ref(tab:linkage) are unconnected, it seems that we are stuck. 

The next section suggests a way out of the dilemma.

## Bridging instruments by mapping items {#sec:mapping}

Many instruments for measuring child development have appeared since the works of @shirley1933 and @gesell1943. It is no surprise that their contents show substantial overlap. All tools assess events like starting to see, hear, smile, fetch, crawl, walk, speak and think. 

We will exploit the overlap to bridge different instruments. For example, Table \@ref(tab:example2words) displays the labels of milestones from six instruments. All items probe the ability of the child to formulate "sentences" of two words.

```{r example2words, echo = FALSE}
items <- c("by1mdd136", "by2mdd114", "ddicmm041", "denlgd019",
           "grihsd217", "vinxxc016")
labels <- dscore::get_labels(items)
df <- tibble::tibble(Item = items, Label = labels)
t <- knitr::kable(df, booktabs = TRUE, 
             caption = "Example of similar items from different instruments.")
kableExtra::column_spec(t, 1, monospace = TRUE)
```
&nbsp;


The idea is to check whether these milestones measure development in the same way. If this is found to be accurate, then we may formally restrict the difficulty levels of these milestones to be identical. This restriction provides a formal bridge between the instruments. We repeat the process for all groups of similar-looking items.

A first step in the bridging process is to group items from different instruments by similarity. As the `by3` is relatively long and is the most often used instrument, it provides a convenient starting point. Subject matter experts experienced in child development mapped items from other tools to `by3` items. These experts evaluated the similarity of wordings and descriptions in reference manuals. Also, they mapped same-skill items across other instruments into groups if these did not map onto `by3` items.

We order item mappings into five domains: fine motor (FM), gross motor (GM),
cognitive (COG), receptive (REC) and expressive (EXP). Figure
\@ref(fig:mappingshiny) displays the connections between the instruments via the
item groups in each domain. With the `Prev` and `Next` buttons you can click
through the five domains. The items are displayed as the leafs and are colored
by instrument. The lines display the links between the items (and
instruments). Hovering over the items highlights the item and its connections to others.

```{r mappingshiny, echo = FALSE, fig.align="center", fig.cap='(ref:mappingshiny)', fig.keep='all', fig.width=10}
knitr::include_app("https://tnochildhealthstatistics.shinyapps.io/GCDG_mapping/", 
  height = "700px")
```
(ref:mappingshiny) Connections between the instruments via mapped item groups in each domain.


## Age profile of item mappings {#sec:viewmapping}

```{r plot_p_a_eq, include=FALSE}
model <- dmetric::model_lean
model$active_equates <- NULL #to remove "ACTIVE" tag, because these are pre-modeling examples
lean <- dmetric::gcdg_lean
eq_plots <- plot_p_a_equate(lean, model, equates = c("COG36", "FM38", "EXP12", "COG24"), passive = TRUE, show_fit = FALSE)
```



One way to explore the similarity of milestones from different instruments is to plot the probability of passing by age. Figure \@ref(fig:poteq) shows two examples.The first graph presents the age curves of a group of four cognitive items that assess the ability to put a cube or block in a cup or box. The milestones are administered in different studies and seem to work similarly. The second plot shows a similar graph for items that assess the ability to build a tower of six cubes or blocks. These milestones have similar age patterns as well.

```{r poteq, echo=FALSE, fig.height=10, fig.width=10, fig.keep='all', warning=FALSE, results='hide', fig.cap = '(ref:poteq)'}
##promising equates
gridExtra::grid.arrange(
  eq_plots[["COG36"]],
  eq_plots[["FM38"]]
)

```
(ref:poteq) The probability of passing by age in potential bridging items.


Figure \@ref(fig:badeq) presents two examples of weak item mappings. Notable timing differences exist for the "babbles" and "bangs" milestones, which suggests that we should not take these as bridges.

```{r badeq, echo=FALSE,  fig.height=10, fig.width=10, fig.keep='all', warning=FALSE, results='hide', fig.cap = '(ref:badeq)'}

##bad equates
gridExtra::grid.arrange(
  eq_plots[["EXP12"]], ## ZA=GRI/BY1; NL=DDI; CL1=BY1
  eq_plots[["COG24"]] ## BR1=den; CO2=den; CL1=BY1; ZA=BY1
)
```
(ref:badeq) Probability to pass items for age in poor bridges.

 

While these plots are suggestive, their interpretation is surprisingly complicated. We may find that age profiles of two milestones *A and B* administered in samples 1 and 2 respectively *are identical* if

* A and B are equally difficult and samples 1 and 2 have the same maturation level;
* A is more difficult than B and sample 1 is more advanced than 2.

Similarly, we may find that the age profile for *A is earlier than B* if

* A is easier than B and if samples 1 and 2 have the same level of maturation;
* A and B are equally difficult and if sample 1 is more advanced than sample 2.

Note that the age curves confound difficulty and ability, and hence cannot be used to evaluate the quality of the item map. 

What we need to do is separate difficulty and ability. For this, we need a formal statistical model. The next chapter introduces the concepts required in such a model.
