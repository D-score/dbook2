[
["index.html", "D-score: Tuning instruments to unitiy Welcome", " D-score: Tuning instruments to unitiy Editor: Iris Eekhout (Netherlands Organization for Applied Scientific Research TNO, Leiden) Welcome The \\(D\\)-score is a one-number summary that quantifies generic development of children. Here you find introductory booklets on the \\(D\\)-score, each of which addresses a particular aspect of the general idea. The \\(D\\)-score booklet series consists of the following titles: \\(D\\)-score: Turning milestones into measurements \\(D\\)-score: Tuning instruments to unity \\(D\\)-score: Tailoring tests to fit the occasion Booklet I is currently available as complete draft. Booklets 2 and 3 are planned for 2019 and 2020. This work is kindly supported by the knowledge integration (ki) program of the Bill &amp; Melinda Gates Foundation. If you have any suggestions or comments, please let me know. "],
["section-ch-introduction2.html", "Chapter 1 Introduction", " Chapter 1 Introduction Booklet I D-score: Turning milestones into measurement highlights the concepts and tools needed to obtain a quantitative score from milestones from an instrument. Once we have such a score, we may Compare development within the same child over time; Compare development of two children of the same age; Compare development of two children at different ages; Compare development of groups of children at different ages; And so on… In practice, the problem is more complicated. There are about 150 different instruments to measure child development. (Fernald et al. 2017) In principle, one could apply the methodology of booklet I to each instrument separately. Every instrument would thus define its own quantitative scale. The problem with this approach is that measurements made on those scales cannot be compared to each other. More in particular, scores will be specific to the milestones, study samples, and the domain coverage of the particular instrument. In sum, we wouldn’t be able to compare development across instruments, a major impediment. What is needed instead is either Everybody uses the same instrument; We extract comparable scores from different instruments. Option 1 seems easy, but may effectively halt the science of measuring child development. Until we have the perfect instrument option 2 is the only realistic choice. In this booklet we aim to exploit the overlap between instruments to create comparable scores. For example, most instruments have milestones like Can stack two blocks, Is able to stand or Says baba. By carefully mapping out the similarities between instruments we are able constrain the statistical model in a sensible way. As a result, we can map different instruments onto the same scale. "],
["section-sdg-4-2-1-indicator.html", "1.1 SDG 4.2.1 indicator", " 1.1 SDG 4.2.1 indicator "],
["section-quick-scan-of-instruments.html", "1.2 Quick scan of instruments", " 1.2 Quick scan of instruments "],
["section-care-giver-vs-direct-assessment.html", "1.3 Care-giver vs direct assessment", " 1.3 Care-giver vs direct assessment "],
["section-individual-programmatic-population-settings.html", "1.4 Individual-programmatic-population settings", " 1.4 Individual-programmatic-population settings "],
["section-ch-data.html", "Chapter 2 Data", " Chapter 2 Data In this booklet we explain the methodology that we used to obtain one score for Development (\\(D\\)-score) that is globally interprettable. This chapter introduces the data that we use to illustrate our methodology. The data originates from a study by the Global Child Development Group (GCDG) gathering child development data from 16 cohorts. Overview of cohorts and instrument (2.1) Cohort descriptions (2.2) Instruments (2.3) "],
["section-sec-gcdgoverview.html", "2.1 Overview of cohorts and instruments", " 2.1 Overview of cohorts and instruments The Global Child Development Group (GCDG) collected data from 16 cohorts. The objective of the study was to develop a population-based measure to monitor early child development across ages and countries. The requirements for inclusion were direct assessment of child development; availability of individual milestone scores; spanning ages between 0-5 years; availability of follow-up measures, at ages 5-10 years. The effort resulted in a database containing individual data from over 16,000 children from 11 countries. The world map below (Figure: 2.1) colors the countries included in the study. Section 2.2 briefly describes each cohort. Section 2.3 reviews the measurement instruments. Figure 2.1: Coverage of countries included in the study. The GCDG data comprises of birth cohorts, impact evaluation studies and instrument evaluation studies. Table 2.1 displays a brief overview of the instruments used in each sub-study. Table 2.1: Overview of instruments administered in the cohorts. Cohort by den gri bat vin ddi bar tep asq sbi Bangladesh x Brazil 1 x Brazil 2 x Chile 1 x Chile 2 x x China x Colombia 1 x Colombia 2 x x x x Ecuador x Ethiopia x Jamaica 1 x Jamaica 2 x Madagascar x Netherlands1 x Netherlands2 x South Africa x x x "],
["section-sec-cohorts.html", "2.2 Cohort descriptions", " 2.2 Cohort descriptions The cohorts have different designs, age ranges and assessment instruments. In Figure 2.2 for each cohort the age range for the development assessments is displayed colored by the developmental instruments that were used. Below the Figure a brief description of each cohort is written. Figure 2.2: Age range and assessment instrument of included data for each GCDG cohort The Bangladesh study (GCDG-BGD-7MO) was an impact evaluation study including 1862 children around the age of 18 months. The Bayley Scale for Infant and Toddler Development-II (by2) was administered and long-term follow-up data were available for the Wechsler Preschool and Primary Scale of Intelligence (WPPSI) at 5 years (Tofail et al. 2008). The Brazil 1 study (GCDG-BRA-1) was a birth-cohort with 3 measurement moments: 644 children at 3 months, 1412 children at 6 months and 1362 children at 12 months. In each round, the Denver Developmental Screening Test-II (den) was administered. Long-term follow-up data were available for the Wechsler Adult Intelligence Scale (WAIS) at 18 years (Victora et al. 2006). The Brazil 2 study (GCDG-BRA-2) was a birth-cohort with measurements of 3907 children at 12 months and 3869 children at 24 months. On both occasions the Battelle Development Inventory (bat) was administered (Moura et al. 2010). The Chile 1 study (GCDG-CHL-1) was an impact evaluation study of 128 children assessed at 6 months, 1732 children at 12 months and 279 at 18 months. The by1 was administered at each wave. Long-term follow-up data were available for the WPPSI at 5-6 years (Lozoff et al. 2003). The Chile 2 study (GCDG-CHL-2) was a birth-cohort of 4869 children who were administered the Battelle Developmental Inventory (bat) at 7-23 months and 9201 children who were administered the Test de Desarrollo Psicomotor (tep) at 24-58 months. For the latter group, follow-up data were available for the Peabody Picture Vocabulary Test (PPVT) at 5-6 years (Conteras and González 2015). The China study (GCDG-CHN) was an impact evaluation study that contained 990 children assessed with the by3 at 18 months (Lozoff et al. 2016). The Colombia 1 study (GCDG-COL-LT45M) was an impact evaluation study that comprised two waves, wave 1 contained 704 children at 12-24 months and wave 2 631 children at 24-41 months. The by3 was administered at each wave. Long-term follow-up data were available for PPVT at 4-6 years (Attanasio et al. 2014). The Colombia 2 study (GCDG-COL-LT42M) was an instrument validation study where all 1311 children aged 6-42 months were administered the by3. For a subgroup of 658 children the den, the Ages and Stages Questionnaire (asq) and the bat screener were administered as well. Long-term follow-up data were available for the Fifth Wechsler Intelligence Scale for Children (WISC-V) and the PPVT (Rubio-Codina et al. 2016). In Ecuador an impact evaluation study (GCDG-ECU) was performed for 667 children between 0-35 months where the Barrera Moncada (bar) was administered. Long-term follow-up data were available for the PPVT at 5-8 and 9-12 years (Paxson and Schady 2010). The Ethiopia study (GCDG-ETH) was a birth-cohort with 193 children of 12 months in the first wave, 440 children of 30 months at the second wave and 456 children of 42 months at the third wave. At each wave the by3 was administered. Long-term follow-up data were available for the PPVT at 10-11 years (Hanlon et al. 2009). The Jamaica 1 study (GCDG-JAM-LBW) was an impact evaluation study were the Griffiths Mental Development Scales (gri) were administered to 225 children of 15 months at the first wave, and 218 children of 24 months at the second wave. Long-term follow-up data were available for WPPSI and PPVT at 6 years (Walker et al. 2004). The Jamaica 2 study (GCDG-JAM-STUNTED) was an impact evaluation study were the gri were administered to 159 children at 9-24 months, 21-36 months and at 33-48 months. Long-term follow-up data were available for sbi, Raven’s Coloured Progressive Matrices (Ravens), and PPVT at 7-8 years and the WAIS at 17-18 years (Grantham-McGregor et al. 1991). The Madagascar study (GCDG-MDG) was an impact evaluation study where the sbi was administered to 205 children aged 34-42 months. Long-term follow-up data were available for sbi and PPVT at 7-11 years (Fernald et al. 2011). The Netherlands 1 study (GCDG-NLD-SMOCC) was an instrument validation study with a total of 9 waves. At each wave the Dutch Developmental Instrument (ddi) (In the Netherlands known as Van Wiechenschema) was administered. The first wave included 1985 children at 1 month, wave 2 1807 children at 2 months, wave 3 1963 children at 3 months, wave 4 1919 children at 6 months, wave 5 1881 children at 9 months, wave 6 1802 children at 12 months, wave 7 1776 children at 15 months, wave 8 1787 children at 18 months, and wave 9 1815 children at 24 months (Herngreen et al. 1992). The Netherlands 2 study (GCDG-NLD-2) was an instrument validation study with a total of five waves. At each wave the ddi was administered. Wave 1 included 1016 children at 24 months, wave 2 995 children at 30 months, wave 3 1592 children at 36 months, wave 4 1592 children at 42 months, and wave 5 1024 children at 48 months (Doove 2010). The South Africa study (GCDG-ZAF) was a birth cohort with four waves. The first wave included 485 children and second wave 275 children, who were assessed at 6 and 12 months, respectively, with the by1 and the gri. The third wave included 1802 children and the fourth wave 1614 children, assessed at 24 and 48 months, respectively, with the Vineland Social Maturity Scale (vin) (Richter et al. 2007). "],
["section-sec-instruments.html", "2.3 Instruments", " 2.3 Instruments The Bayley Scales for Infant and Toddler Development (by1,by2, by3) aim to assess infants and toddlers, aged 1-42 months. The current version is the by3, but in GCDG cohorts earlier version were also used (i.e. by1 and by2) (Bayley 1969)(Bayley 1993)(Bayley 2006). The 326 items of the by3 measure three domains: Cognitive items, Motor items (with fine and gross motor items) and Language items (with expressive and receptive items). The by2 contains 277 items and has two additional subscales: Social-Emotional and Adaptive Behavior. by1 contains 229 items. The Denver Developmental Screening Test (den) is aimed to identify developmental problems in children up to age six. The 125 dichotomous test items are distributed over the age range from birth to six years. The Denver covers four domains: personal-social, fine motor and adaptive, language, and gross motor. The test items are all directly observed by an examiner and are not dependent on parent report (Frankenburg et al. 1992) (Frankenburg et al. 1990). The Griffiths Mental Development Scales (gri) measure the rate of development in infants and young children in six developmental areas: loco motor, personal-social, hearing and language, eye and hand coordination, performance and practical reasoning (Griffiths 1967). The Battelle Developmental Inventory (bat) measures key developmental skills in children from birth to 7 years, 11 months. The instrument contains 450 items distributed over five domains: adaptive, personal-social, communication, motor, and cognitive (Newborg 2005). The Vineland Social Maturity Scale (vin) is a test to assess social competence. The instrument contains eight subscales that measure communication skills, general self-help ability, locomotion skills, occupation skills, self-direction, self-help eating, self-help dressing and socialization skills (Doll 1953). The Dutch Developmental Instrument (ddi) measures early child development during the ages 0-4 years. The instrument consists of 75 milestone items that are distributed over three domains: fine motor, adaptive, personal and social behavior; communication; and gross motor (Schlesinger-Was 1981). The Barrera Moncada (bar) is a Spanish instrument that measures the growth and psychological development of children (Barrera Moncada 1981). The Test de Desarrollo Psicomotor (tep) is an instrument to evaluate toddlers aged 2 to 5 years on their development. The items are distributed over three sub-tests: 16 items assess coordination; 24 items assess language skills and 12 items assess motor skills (Haeussler and Marchant 1999). The Ages and Stages Questionnaire (asq) measures developmental progress in children between 2 months and 5,5 years. The instrument assess development in five areas: personal social, gross motor, fine motor, problem solving and communication. The asq contains sets of 30 items in 21 age intervals and is completed by the caregiver (Squires and Bricker 2009). The Stanford Binet Intelligence Scales (sbi) is a cognitive ability and intelligence test to diagnose developmental deficiencies in young children. The items are distributed over five subtests: fluid reasoning, knowledge, quantitative reasoning, visual-spatial processing and working memory (Roid 2003)(Hagen and Stattler 1986). "],
["section-ch-comparability.html", "Chapter 3 Comparability", " Chapter 3 Comparability This chapter describes challenges and methodologies to harmonize child development measurements obtained by different instruments: Are instruments connected? (3.1) Bridging instruments by mapping items (3.2) Overview of promising item mappings (3.3) "],
["section-sec-challenge.html", "3.1 Are instruments connected?", " 3.1 Are instruments connected? The ultimate goal is to compare child development across populations and cultures. A complication is that measurements are made by different instruments. To do deal with this issue, we harmonize the data included in the GCDG cohorts. In particular, we process the milestone responses such that the following requirements hold: Every milestone in an instrument has a unique name and a descriptive label; Every milestone occupies one column in the dataset; Item scores are (re)coded as: 1 = PASS; 0 = FAIL; Items not administered or not answered are a missing value; Every row in the dataset corresponds to a unique cohort-child-age combination. Cohorts and milestones need to be connected. There are several ways to connect cohorts: Two cohorts are directly connected if they use the same instrument; Two cohorts are indirectly connected if both connect to a third cohort that connects them. Likewise, instruments can be connected: Two instruments are directly connected if the same cohort measures both; Two instruments are indirectly connected if both connect to a third instrument that connects them. Table 3.1: Linkage pattern indicating combinations of cohorts and instruments. aqi bar bat by1 by2 by3 ddi den gri mac peg sbi sgr tep vin Bangladesh X Brazil 1 X Brazil 2 X Chile 1 X Chile 2 X X China X Colombia 1 X Colombia 2 X X X X Ecuador X Ethiopia X Jamaica 1 X Jamaica 2 X Madagascar X X X Netherlands1 X Netherlands2 X South Africa X X X X An X in Table 3.1 identifies which cohorts use which instruments. The linkage table shows that studies from China, Colombia and Ethiopia are directly connected (by by3). Brazil 1 indirectly connects to these studies through den. Some cohorts (e.g., Chile 1 and Ecuador) do not link to any other study. Likewise, we might say that aqi, bat, by3 and den are directly connected. Note that no indirect connections exist to this instrument group. Table 3.1 is a somewhat simplified version of the linkage pattern. As we saw in section 2.2, there are substantial age differences between the cohorts. The linked instrument linkage table shows the counts of the number of registered scores per age group. What appears in Table 3.1 as one test may actually comprise of two disjoint subsets, and hence some cohorts may not be connected after all. Connectedness is a necessary - though not sufficient - requirement for parameter identification. If two cohorts are not connected, we cannot distinguish between the following two alternative explanations: Any differences between studies can be attributed to the ability of the children; Any differences between studies can be attributed to the difficulties of the instruments. The data do not contain the necessary information to discriminate between these two explanations. Since many cohorts in Table 3.1 are unconnected, it seems that we are stuck. The next section suggests a way out of the dilemma. "],
["section-sec-mapping.html", "3.2 Bridging instruments by mapping items", " 3.2 Bridging instruments by mapping items Many instruments for measuring child development have appeared since the works of Shirley (1933) and Gesell (1943). It is no surprise that their contents show substantial overlap. All tools assess events like starting to see, hear, smile, fetch, crawl, walk, speak and think. We will exploit the overlap to bridge different instruments. For example, Table 3.2 displays the labels of milestones from six instruments. All items probe the ability of the child to formulate “sentences” of two words. Table 3.2: Example of similar items from different instruments. Item Label by1mdd136 sentence of 2 words by2mdd114 Uses a two-word utterance ddicmm041 Says sentences with 2 words denlgd019 Combine Words grihsd217 Uses word combinations vinxxc016 use a short sentence The idea is to check whether these milestones measure development in the same way. If this is found to be accurate, then we may formally restrict the difficulty levels of these milestones to be identical. This restriction provides a formal bridge between the instruments. We repeat the process for all groups of similar-looking items. A first step in the bridging process is to group items from different instruments by similarity. As the by3 is relatively long and is the most often used instrument, it provides a convenient starting point. Subject matter experts experienced in child development mapped items from other tools to by3 items. These experts evaluated the similarity of wordings and descriptions in reference manuals. Also, they mapped same-skill items across other instruments into groups if these did not map onto by3 items. We order item mappings into five domains: fine motor (FM), gross motor (GM), cognitive (COG), receptive (REC) and expressive (EXP). Figure 3.1 displays the connections between the instruments via the item groups in each domain. With the Prev and Next buttons you can click through the five domains. The items are displayed as the leafs and are colored by instrument. The blue lines display the links between the items (and instruments). Figure 3.1: Connections between the instruments via mapped item groups in each domain. "],
["section-sec-viewmapping.html", "3.3 Age profile of item mappings", " 3.3 Age profile of item mappings One way to explore the similarity of milestones from different instruments is to plot the probability of passing by age. Figure 3.2 shows two examples.The first graph presents the age curves of a group of four cognitive items that assess the ability to put a cube or block in a cup or box. The milestones are administered in different studies and seem to work similarly. The second plot shows a similar graph for items that assess the ability to build a tower of six cubes or blocks. These milestones have similar age patterns as well. Figure 3.2: The probability of passing by age in potential bridging items. Figure 3.3 presents two examples of weak item mappings. Notable timing differences exist for the “babbles” and “bangs” milestones, which suggests that we should not take these as bridges. Figure 3.3: Probability to pass items for age in poor bridges. While these plots are suggestive, their interpretation is surprisingly complicated. We may find that age profiles of two milestones A and B administered in samples 1 and 2 respectively are identical if A and B are equally difficult and samples 1 and 2 have the same maturation level; A is more difficult than B and sample 1 is more advanced than 2. Similarly, we may find that the age profile for A is earlier than B if A is easier than B and if samples 1 and 2 have the same level of maturation; A and B are equally difficult and if sample 1 is more advanced than sample 2. Note that the age curves confound difficulty and ability, and hence cannot be used to evaluate the quality of the item map. What we need to do is separate difficulty and ability. For this, we need a formal statistical model. The next chapter introduces the concepts required in such a model. "],
["section-ch-equategroups.html", "Chapter 4 Equate groups", " Chapter 4 Equate groups This chapter introduces the concepts and tools needed to link assessments made by different instruments administered across multiple cohorts. Our methodology introduces the idea of an equate group. Systematic application of equate groups provides a robust yet flexible methodology to link different instruments. Once the links are in place, we may combine the data to enable meta-analyses and related methods. What is an equate group? (4.1) Concurrent calibration (4.2) Strategy to form and test equate groups (4.3) Statistical framework (4.4) Common latent scale (4.5) Quantifying equate fit (4.6) Differential Item Functioning (4.7) "],
["section-sec-eqdef.html", "4.1 What is an equate group?", " 4.1 What is an equate group? An equate group is a set of two or more milestones that measure the same thing in (perhaps slightly) different ways. Table 3.2 contains an example of an equate group, containing items that measure the ability to form two-word sentences. Also, Figures 3.2 and 3.3 show examples of equate groups. Equate groups vary in quality. We can use high-quality equate groups to link instruments by restricting the difficulty of all milestones in the equate group to be identical. Equate groups thus provide a method for bridging different tools. Figure 4.1 displays items from three different instruments with overlapping sets of milestones. The shared items make up equate groups, as displayed by the arrows between them. In the example, all three instruments share one milestone (“walk alone”). The “sitting” and “clap hand” items appear in two tools. So in total, there are three equate groups. Figure 4.1: Example of three instruments that are bridged by common items in equate groups. "],
["section-sec-concurrent.html", "4.2 Concurrent calibration", " 4.2 Concurrent calibration Patterns as in Figure 4.1 occur if we have multiple forms of the same instrument. Although in theory there might be sequence effects, the usual working assumption is that we may ignore them. Equate groups with truly shared items that work in the same way across samples are of high quality. We may collect the responses on identical items into the same column of the data matrix. As a consequence, usual estimation methods will automatically produce one difficulty estimate for that column (i.e. common item). The procedure described above is known as concurrent calibration. See Kim and Cohen (1998) for background. The method simultaneously estimates the item parameters for all instruments. Concurrent calibration is an attractive option for various reasons: It yields a common latent scale across all instruments; It is efficient because it calibrates all items in a single run; It produces more stable estimates for shared items for small samples. However, concurrent calibration depends on a strict distinction between items that are indeed the same across instruments and items that differ. In practice, strict black-white distinctions may not be possible. Items that measure the same skill may have been adapted to suit the format of the instrument (e.g. number of response options, question formulation, and so on). Also, investigators may have altered the item to suit the local language and cultural context. Such changes may or may not affect the measurement properties. The challenge is to find out whether items measure the underlying construct in the same way. In practice, we may need to perform concurrent calibration to multiple - perhaps slightly dissimilar - milestones. When confronted with similar - but not identical - items, our strategy is first to form provisional equate groups. We then explore, test and rearrange these equate groups, in the hope of finding enough high-quality equate groups that will bridge instruments. "],
["section-sec-equaterules.html", "4.3 Strategy to form and test equate groups", " 4.3 Strategy to form and test equate groups An equate group is a collection of items. As a part of concurrent calibration, we may specify that some equate groups are active. The analysis will treat items within such groups as one. The milestones within an active equate group will have the same difficulty estimate. Any remaining equate groups are called passive — the model views milestones within such groups as distinct. The milestones within a passive equate group will have separate difficulty estimates. Active equate groups bridge different instruments. In general, we will set the status of an equate group to active only if we believe that the milestones in that group measure the underlying construct in the same way. Note that this does not necessarily imply that all items need to be identical. In Table 3.2, for example, small differences exist in item formulation. We may nevertheless believe that these are irrelevant and ignore these in practice. Reversely, there is no guarantee that the same milestone will measure child development in the same way in different samples. For example, a milestone like “climb stairs” could be more difficult (and more dangerous) for children who have never seen a staircase. Decisions to activate equate groups should be informed by both subject matter expertise and by the fit to the measurement model. The following steps implement our strategy for forming and enabling equate groups: Content matter experts compare milestones from different instruments and sort similar milestones into equate groups. It may be convenient to select one instrument as a starting point, and map items from others to that (see section 3.2); Visualize age profiles of mapped items (see section 3.3). Verify the plausibility of potential matches through similar age profiles. Break up mappings for which age profiles appear implausible. This step requires both statistical and subject matter expertise; Fit the model to the data using a subset of equate groups as active. Review the quality of the solution and optimize the quality of the links between tools by editing the equate group structure. The technical details of this model are explained in section 4.4. Refit the model until (1) active equate groups link all cohorts and instruments, (2) active equate groups distribute over the full-scale range (rather than being centered at one point); Assess the quality of equate groups by the infit and outfit (see section 4.6). Test performance of the equate groups across subgroups or cohorts by methods designed to detect differential item functioning (see section 4.7). The application of equate groups is needed to connect different instruments to a universal scale. The technique is especially helpful in the situation where abilities differ across cohorts. If the cohort abilities are relatively uniform (for example as a result of experimental design) and if the risk of misspecification of the equate groups is high, a good alternative is to rely on the equality of ability distribution. In our application, this was not an option due to the substantial age variation between cohorts. "],
["section-sec-statisticalframe.html", "4.4 Parameter estimation with equate groups", " 4.4 Parameter estimation with equate groups The Rasch model is the preferred measurement model for child development data. Booklet I: Chapter 4 provides an introduction of the Rasch model geared towards the \\(D\\)-score. The Rasch model expresses the probability of passing an item as a logistic function of the difference between the person ability \\(\\beta_n\\) and the item difficulty \\(\\delta_i\\). Table 4.1 explains the symbols used in equation (4.1). Formula (4.1) defines the model as \\[\\begin{equation} \\pi_{ni} = \\frac{\\exp(\\beta_n - \\delta_i)}{1+\\exp(\\beta_n -\\delta_i)} \\tag{4.1} \\end{equation}\\] One way to interpret the formula is as follows. The logarithm of the odds that a person with ability \\(\\beta_n\\) passes an item of difficulty \\(\\delta_i\\) is equal to the difference \\(\\beta_n-\\delta_i\\) (Wright and Masters 1982). See the booklet I: 4.6.1 logistic model for more detail. In model (4.1) every milestone \\(i\\) has one parameter \\(\\delta_i\\). We extend the Rasch model by restricting the \\(\\delta_i\\) of all items within the same equate group to the same value. We thereby effectively say that these items are interchangeable measures of child development. Estimation of the parameter for the equate group is straightforward. Wright and Masters (1982) present a simple method for aligning two test forms with common items. There are three steps: Estimate the separate \\(\\delta_i\\)’s per item; Combine these estimates into \\(\\delta_q\\) by calculating their weighted average; Overwrite each \\(\\delta_i\\) by \\(\\delta_q\\). Suppose that \\(Q\\) is the collection of items in equate group \\(q\\), and that \\(w_i\\) is the number of respondents for item \\(i\\). The parameter estimate \\(\\delta_q\\) for the equate group is \\[\\begin{equation} \\delta_q = \\frac{\\sum_{i\\in Q} \\delta_iw_i}{\\sum_{i\\in Q} w_i} \\tag{4.2} \\end{equation}\\] Table 4.1: Overview the symbols used in equations (4.1) and (4.2). Symbol Term Description \\(\\beta_n\\) Ability True (but unknown) developmental score of child \\(n\\) \\(\\delta_i\\) Difficulty True (but unknown) difficulty of item \\(i\\) \\(\\delta_q\\) Difficulty The combined difficulty of the items in equate group \\(q\\) \\(\\pi_{ni}\\) Probability Probability that child \\(n\\) passes item \\(i\\) \\(l\\) The number of items in the equate group \\(w_i\\) The number of respondents with an observed score on item \\(i\\) "],
["section-sec-commonscale.html", "4.5 Common latent scale", " 4.5 Common latent scale The end goal for using the equate group method to model development items is to measure development on one common latent scale, the \\(D\\)-score. That way, the measure (i.e. \\(D\\)-score) can be obtained, irrespective of which instrument is used in which population. In Figure 4.2 the \\(D\\)-scores are displayed for three cohorts from the GCDG study: Netherlands 1 (GCDG-NLS-SMOCC), Ethiopia (GCDG-ETH) and Colombia 2 (GCDG-COL-LT42M). As described in section 2.2, the Netherlands 1 study contains the ddi; Ethiopia the by3; and Colombia the by3, den, asq and bdi. Accordingly there is some natural overlap in items between Ethiopia and Colombia via the by3 items. However, the Netherlands 1 cohorts is not linked via the items. In the upper plot, no equate groups were used and in the lower plot, equate groups link the cohorts. Figure 4.2: Example of three cohorts with and without equate group linking. The plot for the model without equate groups shows that the scales for the Ethiopia and Colombia 2 studies are linked naturally via the shared items from by3. The Netherlands 1 cohort is not connected and follows a different track. In the plot for the model with equate groups, the scales for all three cohorts are connected. This example shows that equate groups can bring the abilities for children in different cohorts measured with different instrument onto one scale. "],
["section-sec-equatefit.html", "4.6 Quantifying equate fit", " 4.6 Quantifying equate fit In the Rasch philosophy it is the task of the data to fit the Rasch model. In order to verify the fit of the data to the model, we can assess the item fit and the person fit. Both fit measures are explained thoroughly in Chapter 6 of booklet I. When we use equate groups in the Rasch model, we can also use these fit indices to determine the fit of the items in the equate groups. 4.6.1 Well fitting equate groups The evaluation of equate fit involves comparing the observed probabilities of endorsing the items in the equate group to the estimated probability of endorsing the items in the equate group. In an equate group there is an empirical curve for each item in the equate group and one shared estimated curve. The empirical curves should all be close to the estimated curve for a good equate fit, as presented in the examples in Figure 4.3. Figure 4.3: Two equate groups that present a good equate fit. The equate Turns head to sound of bell is asked in slightly different formats in the Bayley I (by1), Dutch Development Instrument (ddi) and the Denver (den). The three items are combined in an equate group and the empirical data are colored differently for each instrument in the upper plot of Figure 4.3. Equate Walks alone is administered in six different instruments (bar, by1, by2, by3, ddi and gri) and is shown in the lower plot. For both equate groups, the empirical data for each instrument is close to the fitted dashed line, which indicates a good equate fit. The infit and outfit indices, shown in the upper left corners, confirm the good fit (fit &lt; 1). 4.6.2 Equate groups with poor equate fit In modeling with equate groups, selecting the perfect combination of equate groups is a crucial step. Poor fitting equate groups need to be set as passive equate groups, such that the items in the group are not restricted to the same difficulty anymore. In a poor fitting equate group, the empirical curves for each item in the equate group are not close to the shared estimated curve. Additionally, the fit indices show poor fit as well (fit &gt; 1). Two examples of poor equate fit are shown in Figure 4.4. Figure 4.4: Two equate groups that present a poor equate fit. The equate Bangs in play / Bangs 2 blocks is asked in two different instruments, the Bayley I (by1) and the Denver (den). The empirical curve for the by1 item is not close to the fitted curve. The fitted curve is closer to the den item, which suggests that the equate difficulty is mostly based on the den item data. The fit indices are both larger than 1 also indicating the poor fit. The equate Jabbers expressively is asked in different forms in three instruments (i.e. by1, ddi, and gri). The empirical curves, with different colors for ech instrument, are not close to each other, nor close to the fitted curve. Also for this equate the fit indices confirm the poor fit (fit &gt; 1). Both equates should be deactivated in an updated model. "],
["section-sec-equatedif.html", "4.7 Differential item functioning", " 4.7 Differential item functioning An important assumption for equate groups is that the items in the group work in the same way across the different cohorts, i.e., there is no differential item functioning. This means that the items in the equate group are equally difficult for children in different cohorts. This assumption is critical for active equate groups. If it is not met, restricting the difficulty parameters as equal across cohorts may introduce unwanted bias in comparisons between cohorts. 4.7.1 Good equate group without DIF In Figure 4.5, two active equate groups are displayed with empirical curves in different colors for each cohort. In both equate groups the curves are close to each other and to the fitted dashed curve. The lack of difference between the curves for the different cohorts, shows that there is no different equate functioning (i.e. different item functioning, DIF) between the cohorts. Figure 4.5: Two equate groups that present no differential item functioning between cohorts. 4.7.2 Poor equate groups with DIF for study In Figure 4.6, two passive equate groups are displayed, that show differential item functioning between cohorts. The empirical curves are displayed for each cohort separately in different colors. The difference between these curves shows the differential item functioning. For example, the item Throws ball, is easier for children in the South-Africa cohort (purple curve; GCDG-ZAF), and more difficult for children in Colombia (blue curve; GCDG-COL-LT42M). In other words, the probability to pass the item given the \\(D\\)-score (i.e. item difficulty) differs between the cohorts. The same goes for the item Says more than 5 words, which is easier for children in Jamaica (yellow and pink curves; GCDG-JAM-LBW and GCDG-JAM-SUNTED) and more difficult for children in Ecuador (green; GCDG-ECU). Figure 4.6: Two equate groups that present differential item functioning between cohorts. "],
["section-ch-modelingequates.html", "Chapter 5 Modeling equates ", " Chapter 5 Modeling equates "],
["section-gcdg-data-design-and-description.html", "5.1 GCDG data: design and description", " 5.1 GCDG data: design and description Chapter 2.1 provides an overview of the data collected by Global Child Development Group. The group collected item level measurements obatined on 12 instruments for measuring child development across 16 cohorts. We coded every items as 0 (fail), 1 (pass) or missing. The Battelle Developmental Inventory scores items as 0 (fail), 1 or 2, depending on the level of skill demonstrated or time taken to complete the task. We joined categories 1 and 2 of these items. The ASQ items were originally scored as 0 (not yet), 5 (sometimes) and 10 (succeeds). We recoded both 5 and 10 to 1. We concatenated the datasets from these cohort. The resulting data matrix has 71403 rows (child-visit combinations) and 1572 columns (items) collected from 36345 unique children. We removed 233 items that had fewer than 10 observations in a category. The remaining 1339 items were candidates for analysis. The total number of observed scores was equal to about 2.8 million pass/fail responses. While this is a large number of measurements, about 97 percent of the entries in the matrix is missing. Subject matter experts classified items into groups of similar appearing items, thus forming 184 equate groups. Each equate group contains at least two items. "],
["section-modeling-strategies.html", "5.2 Modeling strategies", " 5.2 Modeling strategies The analytic challenge is twofold: to find a subset of items that form a scale; to find a subset of equate groups with items similar enough to bridge instruments. Note that both subsets are related, i.e., changing one affects the other. Thus, we cannot first identify items and then equate groups, or first identify equate groups followed by the items. Rather we need to find the two subsets in an iterative fashion, primarily by hand. This chapter described some of the modelling issues the analyst need to confront. In general, we look for a final model that preserves the items that best fit the Rasch model; uses active equate groups with items that behave the same across many cohorts and instruments; displays reasonable age-conditional distributions of the D-scores under the model; has difficulty estimates that are similar to previous estimates. The modeling strategy is a delicate balancing act to achieve all of the above objective. Particular actions that we could take to improve a given model are: remove bad items; inactivate bad equate groups; break up bad equate groups; move items from one equate group to another; create new equate groups; remove entire instruments; remove persons; remove studies. In order to steer our actions, we look at the following diagnostics (in order of importance): quality of equate group (both visually and through infit); plausibility of the distribution of the D-score by age per study; correspondence of difficulty estimates from published (single study) Dutch data and the new model; infit of the items remaining in the model. Various routes are possible, and may result different final models. The strategy adopted here is to thicken active equate groups by covering as many studies as possible, in the hope of minimizing the number of active equates needed. "],
["section-impact-of-number-of-active-equate-groups.html", "5.3 Impact of number of active equate groups", " 5.3 Impact of number of active equate groups Figure 5.1: D-score by age of four models with all 1339 items using 0, 11, 33 and 184 active equate groups. The number of equate groups has a substantial effect on the D-score distribution. Use the arrows to see other cohorts. Click ZOOM to enlarge the display. Figure 5.1 is a display of the D-score by age for all 16 cohorts under four models. As a rough reference to compare, the gray curves in the back represent the Dutch model as calculate from the SMOCC study. In order to speed up calculation, the figure shows a random subsample of 25% of all points. Manipulate the plot controls to switch cohorts. All models contain 1339 items, but differ in the number of active equate groups. The most salient features per model are: 1339_0: No equate groups, so different instruments in different cohorts are fitted independently; 1339_11: Connects all cohorts through one or more equated items using 11 equate groups in total; 1339_33: There are 33 equate groups that bridge cohort and instruments; 1339_184: Maximally connects instruments and cohort by all equate groups. Comparison of the D-score distibution by age across these models yields various insights: The locations of cohorts on the vertical scale depends on the number of active equate groups. For example, for Madagascar (MDG) the points are located around 52 when no equate groups are actived, whereas if all are activated it about 68. The age trend depends on the number of active equate groups. For example, for Colombia (COL) or Ethiopia (ETH), the model without equate groups has a shallow age trend, whereas it is steep for the 1339_184 model. The vertical spread depends on the number of equate groups. For example, the spread in the Chile-2 (CHL-2) cohort substantially increases with the number of active equates. Model 1339_0 for the Dutch NLD-SMOCC cohort is equivalent to the model fitted to the SMOCC study alone. Introducing equate groups compresses the range of scores, especially at the higher end. We have no seen that the number of active equate groups has a large effect on the model. The next sections looks into the equate groups in more detail. "],
["section-age-profiles-of-similar-milestones.html", "5.4 Age profiles of similar milestones", " 5.4 Age profiles of similar milestones Figure 5.2: Percentage of children that pass similar milestones at a given age. ZOOM Figure 5.2 displays the percentage of children that pass milestones at various ages. Subject matter experts clustered similar items stemming from different instruments into equate groups. There are 184 equate groups that contain two or more milestones. Most age profiles show a rising pattern, as expected, though some (e.g. FM17 or ). Equate EXP26 combines two-word sentences items from seven instruments into one plot. The item difficulties expressed as age-equivalents (c.f. Section 3.1.2, booklet I) for these cohorts vary between 20-25 months. By comparison, equate group EXP18 (jabber expressively) shows more heterogeneity across cohorts, and is therefore less likely to be useful for equating. Equate group is FM31 (stack two blocks) is another example of a promising example. By comparison, FM38 shows additional heterogeneity. As a last example, consider GM42 (walks alone), which has a similar age profiles across cohorts, whereas GM44 (throws ball) or GM49 (walk down stairs) are more heterogeneous. We could follow different strategies in selecting which eqeate group to active. One strategy would be to include as many equate groups as possible (e.g. all 184 equates) so as to build as many bridges as pososble between different instruments. A more selective strategy would be to activate a subset of promising equates and leave others inactive. The following section compares four different approaches. "],
["section-quality-of-equate-groups.html", "5.5 Quality of equate groups", " 5.5 Quality of equate groups Figure 5.3: Percentage of children that pass similar milestones given their D-score as calculated under four models (1339 items, and 0, 11, 33 and 184 equate groups, respectively. ZOOM Figure 5.3 shows how the passing percentage depends on the child’s D-score as calculated under four models. All models include the same 1339 milestones, but differ in the number of active equates. The grey curve corresponds to the estimate made under assumption of that milestones are equally difficult. Good milestones for bridging instruments will have a tight bundle of curves. For example, equate EXP26 has tight bundles especially in models 1339_11 and 1339_33. By comparison, the curves of the two extreme models vary considerably: the model without any bridge (1339_0) or the model with all bridges (1339_184) are thus less than ideal. The shallow grey curve of model 1339_184 indicates a poorer overall fit. Outfit and infit statistics measure the residual deviation of the items to the grey curve. High values (e.g. above 1.4) are undesirable, and indicate lack of fit to the model. For example, the values for model 1339_184 (1.70 and 1.25) indicate a mediocre fit, whereas models 1339_33 and 1339_11 fit well. Sometimes the individual item curves are steeper than the grey curve. This indicates that these milestones are more discriminative than the combined item. Model 1339_0 lacks a grey curve and has no fit statistics because that model does not form the combined item. The probability curves provide a quick visual method for spotting promising and problematic equate groups. Examples of promising equate groups include COG36, FM31, GM26 and GM42. A little more weaker are FM26 (has more variability), FM52 (looks promising, but has a problem with the item grigcd402 from the GCDG_JAM_STUNTED cohort), and GM35 (does not align cohort GCDG-ZAF). In such cases, one may wish to move an item out of an equate group, combine equate groups, or inactivate troublesome links. Until now we only looked at models that include all 1339 items. In practice, we may improve upon the model by selecting that subset of milestones that fit the Rasch model. The next section looks in this modelling step in more detail. "],
["section-milestone-selection.html", "5.6 Milestone selection", " 5.6 Milestone selection Figure 5.4: Infit and outfit of 1339 items in model 1339_11. About 8 percent of the points falls outside the plot. Item infit and outfit are convenient statistics for selecting the milestones that fit the model better. Figure 5.4 displays the infit and outfit statistics of model 1339_11. The correlation between infit and outfit is high (\\(r = 0.84\\)). The expected value of the infit and outfit statistics when the model fits is 1.0. The center of infit and outfit in Figure 5.4 is approximately 1.0, so on average one could say the items fit the model. Note however that fit values above and below the values of 1.0 are qualitively different. Item with fit statistics exceeding 1.0 fit the model less well than expected (underfit), whereas items with fit statistics lower than 1.0 fit the model better than expected (overfit). See Booklet 1: Section 6.1 for more details. Some practitioners remove both underfitting and overfitting items. However, we like to preserve overfitting items and be more strict in removing items that underfit. The idea is that preservation of the best fitting items may increase scale length, and hence reliability and measurement precision. Figure 5.4 draws two cut-off lines at 1.0. Taking items with infit &lt; 1.0 and outfit &lt; 1.0 will select 631 out of 1339 items for further modelling. A practical problem of item removal is that it also affects equate group composition. By default, a removed item will also be removed from the equate group, so item removal may reduce the size of an equate group below two items. For passive equates this is no problem, since passive equates have no effect on the estimates. However, removal of an underfitting item from an active equate group will break the bridge between the instrument it pertains to and the rest of the item set. Potentially this can result in substantial effects on the D-score distribution of the cohort, as demonstrated in Figure 5.1. As a solution, we force any items that are members of active equate groups to remain in the analyis. If that leads to substantially worse equate fit in the next model, we must search for alternative equate groups that bridge the same instruments and that are less sensitive to misfit. "],
["section-other-modelings-action.html", "5.7 Other modelings action", " 5.7 Other modelings action 5.7.1 Instrument fit Figure 5.5: Box plot of the distribution of item outfit per instrument in model 1339_11. Some instruments fit better than others. 5.5 shows the box plots of outfit per instrument. Instruments bar, by1, ddi and vin generally fit well, whereas discrepancies between model and data are larger for bat, by2 and sbi. After systematic exploration, we found that models without bat (Battelle Development Inventory) were able to better discriminate children in the upper range of the D-score scale. We therefore opted to remove bat from the model, even though this meant that one cohort (GCDG-BRA-2) had to be dropped from the analysis. It is not clear why bat does not fit. Some additional modelling experiments showed that is was extremely difficult to get enough high-quality equate groups that link bat to other instruments. Perhaps the scoring system of the Battelle in three categories invokes scoring behavior that is different from PASS/FAIL scoring used by most other instruments. 5.7.2 Splitting and combining equate groups There is no single index of model-data fit that will detect all of the possible disturbances. "],
["section-item-information.html", "5.8 Item information", " 5.8 Item information Item information is a psychometric measure the quantifies the utility of the item, given the ability level. So, depending on the person that fills in the item (i.e. the persons ability level), the item provides a certain amount of information to that persons final \\(D\\)-score. The item information can be calculated as the conditional probability to endorse an item (\\(P(\\hat\\delta_i)\\)) times the conditional probability to fail an item (\\(1-P(\\hat\\delta_i)\\)). Accordingly, the maximum information an item can provide is when the probability to endorse an item is equal to the probability to fail, i.e. when \\(P(\\hat\\delta_i) = 0.5\\). The information is inversely related to the error of measurement, thus more information amouts to less error of measurement. For each item score in the data, we can compute the amount of information it contributed to the model \\(D\\)-score. By summing this information for each item in the model, we can obtain a measure of certainty about the difficulty estimate of the item. This sum of information holds the number of times the item was administered, and the probability of endorsing the item for each assessment. We can grade the items by the information into categories A (best) to D (worst) and visualize how certain we are about the difficulty estimates of the items. In Figure 5.6, the grades are displayed for each item by their difficulty (tau). Most items are graded higher than C, 30 items have an information grade of D and may benefit from more data from future studies. The equate groups are displayed as black asterisk and mostly have grade A. Figure 5.6: Item information grade by item difficulty (tau) for the final model In our model, equate groups are very important and the selection of the best performing item groups was one of the main modelling steps and an important modeling focus. Hence, the information grade for the equate groups in our model is very high (17 equate groups were graded an A and 1 a B). In Table 5.1 the information for each item is displayed with in the “n” column the number of times the items in the equate groups were administered in the data. Table 5.1: Equate group information in the final model. equate tau n info grade EXP2 11.4 3608 162.3 A REC6 30.9 5428 95.4 B GM25 36.4 6380 470.6 A FM26 42.9 4155 296.8 A GM35 44.0 5522 356.0 A COG36 44.5 7912 230.0 A GM42 49.9 5953 327.7 A FM31 53.2 10991 731.7 A COG55 54.1 5647 420.3 A FM72 57.1 5430 253.6 A EXP26 59.1 9119 578.8 A SA1 60.1 3363 172.1 A FM38 60.9 10236 491.7 A FM52 67.8 13487 1159.9 A FM43 69.7 15765 1563.9 A GM60 70.1 9519 1070.6 A REC40 71.0 10393 1182.9 A FM61 72.6 10612 945.9 A "],
["section-ch-ability.html", "Chapter 6 Comparing ability", " Chapter 6 Comparing ability In this chapter the \\(D\\)-score distributions per GCDG cohort are displayed and the impact of measurement error is compared between the cohorts. Additionally the coverage of the developmental domains is displayed for \\(D\\)-score scale and for a single \\(D\\)-score. \\(D\\)-score distribution by study (6.1) Impact of measurement error (6.2) Domain coverage and scores (6.3) "],
["section-sec-dscores.html", "6.1 \\(D\\)-score distribution by study", " 6.1 \\(D\\)-score distribution by study For each study that is included in the GCDG assembly, the \\(D\\)-score can be obtained using the developed global model. In Figure 6.1, the \\(D\\)-score distributions are displayed for each cohort separately. The blue lines in the graphs are the (temporary) references, as explained in 7.2. Figure 6.1: \\(D\\)-score distributions by study. "],
["section-sec-sem.html", "6.2 Impact of measurement error", " 6.2 Impact of measurement error For each estimated \\(D\\)-score from the calibrated model, the precision of the estimate can be determined. This precision can be expressed as the standard error of measurement (\\(sem\\)). The standard error of measurement is inversely related to the number of items. Thus, when more items are administered for a person, the measurement error for the \\(D\\)-score of this person is smaller. As is shown in Figure 6.2, the \\(sem\\) drops fast when the number of items is increased to 15, and still some more until the number of items is 30. More than 30 items has little effect on the \\(sem\\). Figure 6.2: Standard error of measurement (\\(sem\\)) when the number of items increase. The precision of the \\(D\\)-score estimate is also affected by the information that the items that are administered contribute to the \\(D\\)-score. The information that in item contributes is larger when the item discrimminates well between different reponders. Therefore, the information is a function of the probability to endore the item. For example, if the items are too easy and the probability to pass the item given the \\(D\\)-score is \\(P\\) &gt; 0.90, the \\(sem\\) is larger than when the difficulty of the administered items is closer to the \\(D\\)-score (i.e. \\(P\\) = 0.50). The \\(sem\\) for age in GCDG data (see Figure 6.3) shows that for some ages, the \\(sem\\) is larger than for others. This is on the one hand due to the number of items available in that age range, but also to the design of the cohorts where sometimes relatively easy items are administered. Figure 6.3: Standard error of measurement (\\(sem\\)) in each age group. In Figure 6.4, the \\(sem\\) per age group is shown for each cohort separately. This illustrates the differences in design between the cohorts. For example, the Netherlands 1 cohort (GCDG-NLD-SMOCC), the ddi was used as a screener and items had the probability to pass of approximately \\(P\\)=0.80 (quartile range between 0.62 &lt; \\(P\\) &gt; 1.00), and the number of items administered per measurement is about 10 items (quartile range 6 to 12 items). The Colombia 1 cohort (GCDG-COL-LT45M) was an impact evaluation and has administered the by3 where each child answered on average 45 items (quartile range 38 to 57 items) and the probability to pass was approximately \\(P\\) = 0.64 (quartile range between 0.53 &lt; \\(P\\) &gt; 0.79). The latter study has therefore more precise \\(D\\)-score estimates. Figure 6.4: The standard error of measurement (\\(sem\\)) around the age-standardized \\(D\\)-scores (DAZ) per cohort The \\(sem\\) for an entire cohort or sample can be obtained by pooling the individual \\(sem_i\\) using general rule for pooling variances. Accordingly, the \\(sem\\) for a sample is obtained by combining the within variance \\(\\sum{sem_{i}^2}\\) and the between variance \\(\\sigma_d\\) as in equation (6.1) \\[\\begin{equation} sem = \\sqrt{\\frac{\\sum{sem_{i}^2} + \\sigma_d }{N-1}} \\tag{6.1} \\end{equation}\\] In Figure 6.5 the sample \\(sem\\) per cohort is displayed. The lowest sample \\(sem\\) is found in the Ethiopia study (GCDG-ETH) and the highest in the South Africa cohort (GCDG-ZAF). This can be explained on the one hand by the number of items per child, and on the other hand the difficulty of the administered items (i.e. the item information). Figure 6.5: Standard Error of Measurement (\\(sem\\)) per cohort. Table 6.1 shows the median number of items per child (test length) and the probability to pass the items. In the Ethiopia cohort (GCDG-ETH) 39 items were administered with a median probability of 0.66 and in the South Africa study (GCDG-ZAF) just 12 items with a median probability of 1. Accordingly, in the Ethiopia study more items were administered per child that also have a high level of information for the \\(D\\)-scores. In the South Africa study only few items were administered per child that were also relatively easy and therefore contained less information for the \\(D\\)-scores. Table 6.1: Test length and probability to pass the items per cohort cohort test length (median) pass probability (median) GCDG-ETH 39 0.66 GCDG-CHL-1 32 0.67 GCDG-COL-LT45M 45 0.64 GCDG-COL-LT42M 61 0.62 GCDG-JAM-LBW 43 0.55 GCDG-CHN 27 0.50 GCDG-JAM-STUNTED 38 0.65 GCDG-CHL-2 33 0.48 GCDG-BGD-7MO 14 0.38 GCDG-MDG 8 0.35 GCDG-BRA-1 18 0.89 GCDG-NLD-SMOCC 10 0.80 GCDG-NLD-2 11 1.00 GCDG-ECU 3 0.67 GCDG-ZAF 12 1.00 "],
["section-sec-domains.html", "6.3 Domain coverage and scores", " 6.3 Domain coverage and scores The \\(D\\)-score is a one number score that measures early child development. To evaluate the content validity of the \\(D\\)-score we can make sure that all developmental domains are fairly represented. We distinguish five domains for child development: Fine Motor, Gross Motor, Expressive, Receptive, Cognitive. 6.3.1 Domain coverage of the scale The items in the \\(D\\)-score model can be linked to one or more domains and the cumulative item information to the \\(D\\)-score for each domain can be evaluated. In Figure 6.6, the coverage of the domains for the \\(D\\)-score is displayed. This shows that at lower levels of the \\(D\\)-score, gross motor development is more dominant and that at higher levels of the \\(D\\)-score the cognitive and language domains increase in importance. Figure 6.6: Domain coverage of the \\(D\\)-score scale. Note that for some items the domain allocation is missing. 6.3.2 Domain \\(D\\)-scores It is possible to calculate a \\(D\\)-score that is more representative for a specific domain using the current \\(D\\)-score model. We can use only the items that load to the domain in question to calculate the \\(D\\)-score for that specific domain. Since items may relate to multiple domain, an item can contribute to multiple domain specific \\(D\\)-scores. As the \\(D\\)-score methodology is developed to measure a single construct for development, the domain \\(D\\)-scores correlate highly (\\(r &gt; 0.95\\)). However, these scores can potentially inform on the cohort level (Figure 6.7) or the individual level (see Figure ??). Figure 6.7: Domain \\(D\\)-scores per cohort. In Figure ?? example scores are displayed for a 3 year old boy from the Chili 2 (GCDG-CHL-2) cohort. The filled bars display the available items per domain. Note that the number of items for Gross Motor is very low (only 3 items). The white overlayed line at 5 items, indicates the bare minimum for a \\(D\\)-score. The grey vertical line displays the overall \\(D\\)-score (38.55\\(D\\)) with the \\(sem\\) (0.53) around as the dashed lines. The colored points are the domain \\(D\\)-scores with the \\(sem\\) around in error bars. This plot shows that for the language domains (i.e. Expressive and Receptive), this boy scores relatively low as compared to the motor and cognitive domains. "],
["section-ch-SDGindicator.html", "Chapter 7 SDG 4.2.1 Indicator", " Chapter 7 SDG 4.2.1 Indicator This chapter explains how the \\(D\\)-score can be used to indicate on-track development. The methodology to define on-track development is described and country-level estimates are displayed. Additionally, the indicator is compared to other estimates. Application I: Estimating the SDG 4.2.1 indicator from existing data (7.1) Definition developmentally on track (7.2) Country-level estimates (7.3) Relation to other estimates (7.4) "],
["section-sec-application1.html", "7.1 Application I: Estimating the SDG 4.2.1 indicator from existing data", " 7.1 Application I: Estimating the SDG 4.2.1 indicator from existing data Sustainable Development Goal number 4 is to ensure inclusive and equitable quality education and promote lifelong learning opportunities for all. Target 4.2 is to ensure that by 2030, all girls and boys have access to quality early childhood development, care and pre-primary education so that they are ready for primary education. Indicator 4.2.1 is to measure the proportion of children under 5 years of age who are developmentally on track in health, learning and psycho-social well-being, by sex. Figure 7.1: Sustainable Development Goal 4. The \\(D\\)-score can be obtained from any instrument that is included in the calibrations for the score. This makes the \\(D\\)-score suited as a global score for development. Accordingly, the \\(D\\)-score can be used for the SDG 4.2.1 indicator and interpreted as the global measure for development. In the cohorts that are currently included in the GCDG study, a wide range of countries are represented (see Section 2.1). Combining existing data from such a wide range of countries to create the \\(D\\)-score, broadens the interpretation of the \\(D\\)-score. Nevertheless, for obtaining accurate references that represent world-wide population, more representative (existing) data needs to be added. "],
["section-sec-references.html", "7.2 Definition developmentally on track", " 7.2 Definition developmentally on track For child growth, (global) standards are published by the World Health Organization (WHO) that are used to monitor growth in children and to define whether children are on track. Growth standards are defined for weight-for-age, length/height-for age, weight-for-length/height, etc. In 2006, the methods for constructing a growth reference were reviewed by statisticians and growth experts that resulted in an advised strategy for constructing growth standard (Borghi et al. 2006). A similar strategy can be used to construct a reference standard child development-for-age. This reference standard can then be used to determine whether children are developmentally on track. In Figure 7.2, the strategy for constructing standards for development and to use them to define on track development is visualized in several steps. By clicking ‘Next’, the following step will show in the plot. Figure 7.2: Illustration of the method to define on-track development In the first step the \\(D\\)-score is plotted by age. In the second step, this relation is modeled in an LMS model. The goal of an LMS model is to describe the relation of the \\(D\\)-score by age with age-conditional z-scores. This is done by three smoothed curves representing the median, coefficient of variation and the skewness. In step 3 the centile lines for this model are presented. The resulting age-standardized scores for development (DAZ), are plotted in step 4. In step 5 the standar deviation lines are drawn to indicate an 1 and 2 standard deviation from the mean. The DAZ is used to define on-track development. So \\(D\\)-scores within 2 standard deviations from the median can be defined as on-track. Scores that are more than two standard deviation below the median, can be defined as off-track (red dots). Note that the current reference is based on the GCDG study. The cohorts that are currently included are representing a wide range of countries. However, they are not representative for a global population. The current reference standards are therefore temporary and should be improved when more data are available. "],
["section-sec-countrytrack.html", "7.3 Country-level estimates", " 7.3 Country-level estimates For each age-\\(D\\)-score combination, a standardized score (DAZ) can be calculated. That way we can calculate the DAZ in each country that is included in the current GCDG study. By using the -2SD rule, we can obtain the percentage on-track development for each country. Table 7.1: Percentage of on-track children per country country on-track BGD 0.95 BRA 0.99 CHL 0.98 CHN 1.00 COL 0.99 ECU 0.94 ETH 0.99 JAM 1.00 MDG 0.97 NLD 0.97 ZAF 0.97 "],
["section-sec-otherestimates.html", "7.4 Relation to other estimates", " 7.4 Relation to other estimates In the publication on the global \\(D\\)-score from the GCDG project (Weber et al. 2019), the concurrent, discriminant and predictive validity of the \\(D\\)-score is thoroughly presented and discussed. In this paragraph we mainly focus on stunting, which is commonly used to express impaired growth in children due to nutrition problems. 7.4.1 Stunting The WHO defines stunted as when the height-for-age is more than two standard deviations below the WHO Child Growth Standard median. In Figure 7.3 we compare the percentage stunted to the percentage off-track development in each country. The percentages of stunting differ a lot from the off-track developmental percentages. This indicates that “growth” and “development” are very different constructs. Figure 7.3: Percentage off-track development and stunted per country However, we can see a relation between stunting and development (\\(D\\)-score). When we compare the Standardized \\(D\\)-score (DAZ) in each country for the stunted versus not-stunted children (Figure 7.4). The DAZ for the stunted children is always lower in comparison with the not-stunted children. Figure 7.4: DAZ for stunted versus not-stunted per country "],
["section-ch-ontrack.html", "Chapter 8 Who is on-track?", " Chapter 8 Who is on-track? In the previous chapter 7 we described how to determine off-track development to be used as SDG indicator for early child development. In the current chapter we describe the group that is on-track and what explanatory factors relate to early child develoment. We will order these explanatory factors to relative importance and relate them to opportunities for interventions. Application II: What determines who is developmentally on-track (8.1) Types of explanatory factors (8.2) Relative importance (8.3) Opportunities for intervention (8.4) "],
["section-sec-application2.html", "8.1 Application II: What determines who is developmentally on-track?", " 8.1 Application II: What determines who is developmentally on-track? There are several methodologies available to define on-track development. It is possible to define on-track development based on expert opinion, where many experts are consulted to formulate a definition based on their experience and subject matter knowledge. Another option is to define on-track development based on (representative) population data. The methodological process to develop such a reference is visualized in Figure 7.2 in section 7.2. Ideally, the data used to define a reference is representative for the norm population. In this study we do define on-track development as having \\(D\\)-scores within 2 standard deviations from the median, more specifically, \\(D\\)-scores not more than two standard deviation below the median. The \\(D\\)-scores in the green-shaded area in Figure 8.1 are considered as on-track. However, the references used are based on the data from the included cohorts in this study and may not be representative for the global population. Figure 8.1: \\(D\\)-score observatations that are on-track according the current references. "],
["section-sec-factors.html", "8.2 Types of explanatory factors", " 8.2 Types of explanatory factors There are many known factors that relate to early child development. For example, the educational level of the parents is positively related to development, but also environmental factors such as nutritional status or medical factors such as disease history or birth defects. Unfortunately, we do not have all of these factors measured in our data, but for some factors we can describe the frequency distributions for the on-track children versus off-track children. Table 8.1 displays the background characteristics for the children that are on-track versus off-track for development. We can see some differences between the countries and cohorts, but the differences seem small. For mothers education we can see that the higher the educational level, the lower the off-track percentages. And for the residential area we see that the percentage on-track seems higer in the more rural areas. Table 8.1: Descriptive table for on-track versus off-track development On-track Off-track n % n % cohort GCDG-BGD-7MO 1734 0.949 93 0.051 GCDG-BRA-1 5447 0.995 29 0.005 GCDG-CHL-1 2017 0.999 3 0.001 GCDG-CHL-2 16071 0.980 322 0.020 GCDG-CHN 981 0.999 1 0.001 GCDG-COL-LT42M 1298 0.990 13 0.010 GCDG-COL-LT45M 2557 0.987 34 0.013 GCDG-ECU 621 0.939 40 0.061 GCDG-ETH 2545 0.993 17 0.007 GCDG-JAM-LBW 873 0.995 4 0.005 GCDG-JAM-STUNTED 1425 0.996 6 0.004 GCDG-MDG 197 0.966 7 0.034 GCDG-NLD-2 14313 0.984 228 0.016 GCDG-NLD-SMOCC 136149 0.966 4797 0.034 GCDG-ZAF 8398 0.978 193 0.022 country BD 1734 0.949 93 0.051 BR 5447 0.995 29 0.005 CL 18088 0.982 325 0.018 CN 981 0.999 1 0.001 CO 3855 0.988 47 0.012 EC 621 0.939 40 0.061 ET 2545 0.993 17 0.007 JM 2298 0.996 10 0.004 MG 197 0.966 7 0.034 NL 150462 0.968 5025 0.032 ZA 8398 0.978 193 0.022 maternal education no education 3672 0.977 87 0.023 any primary 52919 0.962 2085 0.038 any secondary 93433 0.972 2706 0.028 higher secondary 28403 0.978 625 0.022 sex female 91695 0.974 2470 0.026 male 88616 0.966 3088 0.034 residence rural 2717 0.991 24 0.009 semi-urban 4685 0.984 78 0.016 urban 120983 0.967 4193 0.033 metropolitan 38023 0.977 901 0.023 birth weight &lt;2500gr 11003 0.924 901 0.076 &gt;2500gr 165460 0.973 4561 0.027 * children with missing data in daz scores are excluded "],
["section-sec-importance.html", "8.3 Relative importance", " 8.3 Relative importance The explanatory variables described in the previous section 8.2 differ in their importance to explain early child development. The explanatory factors that were measured in this study (i.e. country, sex, birth weight, maternal education, height for age and residential area) combined, explain about 6.5% of the variance in the standardized \\(D\\)-score for age. In Figure 8.2 is shown that country differences explain about half of these 6.5% in the \\(D\\)-score. Birth weight is the second important factor. Figure 8.2: Relative importance of the explanatory factors in this study "],
["section-sec-intervention.html", "8.4 Opportunities for intervention", " 8.4 Opportunities for intervention From the analyses performed in the previous sections, we cannot yet formulate a clear advise on opportunities for intervention. The data that we have available is too limited and includes only a small set of explanatory variables and possible preditors for early child development. We can see, however, that there are country differences in early child development, and that supports that interventions should be costumized at country level. "],
["section-ch-discussion2.html", "Chapter 9 Discussion ", " Chapter 9 Discussion "],
["section-potential-and-limitations-of-existing-data-for-sdg-4-2-1.html", "9.1 Potential and limitations of existing data for SDG 4.2.1", " 9.1 Potential and limitations of existing data for SDG 4.2.1 The \\(D\\)-score is a measure that fits perfectly to the current need of comparable global figures for child development status. A measure for early child development that can be interpreted everywhere can either be achieved by having one instrument that is used globally, or by enabling the calculation of a score on a scale that can be obtained from many different instruments. The \\(D\\)-score is the latter, and since the first option would be desirable but at this moment unfeasible, the \\(D\\)-score can in relatively short time give insight in global differences in early child development. As such, the \\(D\\)-score can be used for SDG 4.2.1. However, there are still some limitations, that in time, can be diminished. First, not all instruments that measure early child development are currently included in the \\(D\\)-score key. We are working on expanding the key and additional instruments are added (refer to GSED). Second, the references that can currently be obtained from the \\(D\\)-score that may be used to calculate indices for early child development, are based on the data from different kinds of studies. Since these are not all population studies and some were targeted at specific groups of children, generalization of the scores is not always perfect. So, including more population representative data will improve generalization of the \\(D\\)-score as a global score. Will the addition of new data change the \\(D\\)-score model and metric? It may be possible that the key changes, but we expect that changes are minor. The model that is used now, fits the data well and is developed with great care. "],
["section-options-for-improving-health-policy.html", "9.2 Options for improving health policy", " 9.2 Options for improving health policy "],
["section-suitability-of-d-score-metric.html", "9.3 Suitability of D-score metric", " 9.3 Suitability of D-score metric The \\(D\\)-score metric represents child development very well. Items from the most widely used instruments (such as Bayley, ASQ, Denver, etc) are included. Also, the child development domains are well represented over the entire scale. However, the \\(D\\)-score may not be well suited to screen for domain specific problems. For that purpose, other metrics may be used or developed that are specifically targeted to detect domain specific problems. "],
["section-suggestions-for-better-measurement.html", "9.4 Suggestions for better measurement", " 9.4 Suggestions for better measurement The \\(D\\)-score can be measured well by the instruments that are included in the current model, provided that the items that are included are corresponding to the targeted age group. In Table … an overview of the items included for each instrument per age is presented. The \\(D\\)-score model enables the possibility to create new instruments that can be customized to the exact needs of the study. Population based studies may require a quick measure by less items and are targeted to a well measured population estimate for development. Whereas intervention studies need a precise estimate for the intervention and control group. At the personal level, studying one child’s development, a more precise estimation may be required. Of each of these scenarios, different instruments can be created. In our third booklet, we will discuss all of these options, and more. "],
["section-references.html", "References", " References Attanasio, Orazio P, Camila Fernández, Emla O A Fitzsimons, Sally M Grantham-McGregor, Costas Meghir, and Marta Rubio-Codina. 2014. “Using the infrastructure of a conditional cash transfer program to deliver a scalable integrated early child development program in Colombia: cluster randomized controlled trial.” BMJ (Clinical Research Ed.) 349 (sep29 5): g5785. https://doi.org/10.1136/bmj.g5785. Barrera Moncada, G. 1981. “Crecimiento Y Desarrollo Psicológico Del Niño Venezolano.” Ediciones psicopediátricas. Caracas. Bayley, N. 1969. “Bayley Scales of Infant Development.” New York: Psychological Corp. ———. 1993. “The Bayley Scales of Infant Development-Ii.” San Antonio, TX: Psychological Corporation. ———. 2006. “Bayley Scales of Infant and Toddler Development–Third Edition: Technical Manual.” San Antonio, TX: Harcourt Assessment. Borghi, E, M de Onis, C Garza, J Van den Broeck, E A Frongillo, L Grummer-Strawn, S Van Buuren, et al. 2006. “Construction of the World Health Organization child growth standards: selection of methods for attained growth curves.” Statistics in Medicine 25 (2): 247–65. https://doi.org/10.1002/sim.2227. Conteras, D., and S. González. 2015. “Determinants of early child development in Chile: Health, cognitive and demographic factors.” International Journal of Education and Development 40: 217–30. Doll, E.A. 1953. “The Measurement of Social Competence: A Manual for the Vineland Social Maturity Scale.” Educational Test Bureau, Educational Publishers. Doove, B.M. 2010. “Ontwikkeling kinderen in Maastricht en Heuvelland (MOM), Evaluatie integraal kindvolgsysteem voor signalering in de Jeugdgezondheidszorg: MOMknowsbest.” Maastricht, Netherlands. Fernald, L.C.H., E. Prado, P. Kariger, and A. Raikes. 2017. “A Toolkit for Measuring Early Childhood Development in Low and Middle-Income Countries.” World Bank. Fernald, Lia C H, Ann Weber, Emanuela Galasso, and Lisy Ratsifandrihamanana. 2011. “Socioeconomic gradients and child development in a very low income population: evidence from Madagascar.” Developmental Science 14 (4): 832–47. https://doi.org/10.1111/j.1467-7687.2010.01032.x. Frankenburg, W.K., J. Dodds, P. Archer, H. Shapiro, and Bresnick B. 1992. “The Denver Ii: A Major Revision and Restandardization of the Denver Developmental Screening Test.” Pediatrics 89. Am Acad Pediatrics: 91–98. Frankenburg, W.K., J. Dodds, P. Archer, H. Shapiro, and B. Bresnick. 1990. “The Denver Ii Technical Manual.” Denver, CO: Denver Developmental Materials. Gesell, A. 1943. Infant and Child in the Culture of Today. Los Angeles, CA: Read Book Ltd. Grantham-McGregor, S M, C A Powell, S P Walker, and J H Himes. 1991. “Nutritional supplementation, psychosocial stimulation, and mental development of stunted children: the Jamaican Study.” Lancet (London, England) 338 (8758): 1–5. https://doi.org/10.1016/0140-6736(91)90001-6. Griffiths, R. 1967. “The Abilities of Babies: A Study in Mental Measurement.” University of London Press. Haeussler, I.M., and T. Marchant. 1999. “Tepsi: Test de Desarrollo Psicomotor 2-5 Años.” Eds. Universidad Católica de Chiles. Hagen, E., and J. Stattler. 1986. “Stanford–Binet Intelligence Scales, Fourth Edition.” Thorndike. Hanlon, Charlotte, Girmay Medhin, Atalay Alem, Fikru Tesfaye, Zufan Lakew, Bogale Worku, Michael Dewey, et al. 2009. “Impact of antenatal common mental disorders upon perinatal outcomes in Ethiopia: the P-MaMiE population-based cohort study.” Tropical Medicine &amp; International Health 14 (2): 156–66. https://doi.org/10.1111/j.1365-3156.2008.02198.x. Herngreen, W. P., J. D. Reerink, B. M. van Noord-Zaadstra, S. P. Verloove-Vanhorick, and J. H. Ruys. 1992. “The Smocc-Study: Design of a Representative Cohort of Live-Born Infants in the Netherlands.” European Journal of Public Health 2: 117–22. Kim, Seock-Ho, and Allan S Cohen. 1998. “A Comparison of Linking and Concurrent Calibration Under Item Response Theory.” Applied Psychological Measurement 22 (2): 131–43. Lozoff, Betsy, Isidora De Andraca, Marcela Castillo, Julia B Smith, Tomas Walter, and Paulina Pino. 2003. “Behavioral and developmental effects of preventing iron-deficiency anemia in healthy full-term infants.” Pediatrics 112 (4): 846–54. http://www.ncbi.nlm.nih.gov/pubmed/14523176. Lozoff, Betsy, Yaping Jiang, Xing Li, Min Zhou, Blair Richards, Guobin Xu, Katy M Clark, et al. 2016. “Low-Dose Iron Supplementation in Infancy Modestly Increases Infant Iron Status at 9 Mo without Decreasing Growth or Increasing Illness in a Randomized Clinical Trial in Rural China.” The Journal of Nutrition 146 (3): 612–21. https://doi.org/10.3945/jn.115.223917. Moura, Danilo R, Jaderson C Costa, Iná S Santos, Aluísio J D Barros, Alicia Matijasevich, Ricardo Halpern, Samuel Dumith, Simone Karam, and Fernando C Barros. 2010. “Natural history of suspected developmental delay between 12 and 24 months of age in the 2004 Pelotas birth cohort.” Journal of Paediatrics and Child Health 46 (6): 329–36. https://doi.org/10.1111/j.1440-1754.2010.01717.x. Newborg, J. 2005. “Battelle Developmental Inventory-2nd Edition.” Rolling Meadows, IL: Riverside Publishing. Paxson, Christina, and Norbert Schady. 2010. “Does money matter? The effects of cash transfers on child development in rural Ecuador.” Economic Development and Cultural Change 59 (1): 187–229. http://www.ncbi.nlm.nih.gov/pubmed/20821896. Richter, Linda, Shane Norris, John Pettifor, Derek Yach, and Noel Cameron. 2007. “Cohort Profile: Mandela’s children: the 1990 Birth to Twenty study in South Africa.” International Journal of Epidemiology 36 (3): 504–11. https://doi.org/10.1093/ije/dym016. Roid, G.H. 2003. “Stanford–Binet Intelligence Scales, Fifth Edition.” WPS Psychological Tests. Rubio-Codina, Marta, M Caridad Araujo, Orazio Attanasio, Pablo Muñoz, and Sally Grantham-McGregor. 2016. “Concurrent Validity and Feasibility of Short Tests Currently Used to Measure Early Childhood Development in Large Scale Studies.” Edited by David O. Carpenter. PloS One 11 (8): e0160962. https://doi.org/10.1371/journal.pone.0160962. Schlesinger-Was, E.A. 1981. “Ontwikkelingsonderzoek van Zuigelingen En Kleuters Op Het Consultatiebureau.” Shirley, M. M. 1933. The First Two Years: A Study of Twenty-Five Babies. Vol. II: Intellectual Development. Minneapolis: University of Minnesota Press. Squires, J., and D. Bricker. 2009. “Ages &amp; Stages Questionnaires, Third Edition (Asq- 3). A Parent-Completed Child-Monitoring System.” Paul H. Brookes Publishing Co., Baltimore. Tofail, Fahmida, Lars Åke Persson, Shams El Arifeen, Jena D Hamadani, Ferdina Mehrin, Deborah Ridout, Eva-Charlotte Ekström, Syed N Huda, and Sally M Grantham-McGregor. 2008. “Effects of prenatal food and micronutrient supplementation on infant development: a randomized trial from the Maternal and Infant Nutrition Interventions, Matlab (MINIMat) study.” The American Journal of Clinical Nutrition 87 (3): 704–11. https://doi.org/10.1093/ajcn/87.3.704. Victora, Cesar Gomes, Cora Luiza Pavin Araújo, Ana Maria Batista Menezes, Pedro Curi Hallal, Maria de Fátima Vieira, Marilda Borges Neutzling, Helen Gonçalves, et al. 2006. “Methodological aspects of the 1993 Pelotas (Brazil) Birth Cohort Study.” Revista de Saude Publica 40 (1): 39–46. https://doi.org/10.1590/s0034-89102006000100008. Walker, Susan P, Susan M Chang, Christine A Powell, and Sally M Grantham-McGregor. 2004. “Psychosocial intervention improves the development of term low-birth-weight infants.” The Journal of Nutrition 134 (6): 1417–23. https://doi.org/10.1093/jn/134.6.1417. Weber, Ann M, Marta Rubio-Codina, Susan P Walker, Stef van Buuren, Iris Eekhout, Sally M Grantham-McGregor, Maria Caridad Araujo, et al. 2019. “The d-Score: A Metric for Interpreting the Early Development of Infants and Toddlers Across Global Settings.” Edited by Orazio Attanasio, Gary L Darmstadt, Bernice M Doove, Emanuela Galasso, Pamela Jervis, et al. BMJ Global Health 4 (6). BMJ Specialist Journals. https://doi.org/10.1136/bmjgh-2019-001724. Wright, B. D., and G. N. Masters. 1982. Rating Scale Analysis: Rasch Measurement. Chicago: MESA Press. "]
]
