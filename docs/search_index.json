[
["index.html", "D-score: Tuning instruments to unitiy Welcome", " D-score: Tuning instruments to unitiy Editor: Iris Eekhout (Netherlands Organization for Applied Scientific Research TNO, Leiden) Welcome The \\(D\\)-score is a one-number summary that quantifies generic development of children. Here you find introductory booklets on the \\(D\\)-score, each of which addresses a particular aspect of the general idea. The \\(D\\)-score booklet series consists of the following titles: \\(D\\)-score: Turning milestones into measurements \\(D\\)-score: Tuning instruments to unity \\(D\\)-score: Tailoring tests to fit the occasion Booklet I is currently available as complete draft. Booklets 2 and 3 are planned for 2019 and 2020. This work is kindly supported by the knowledge integration (ki) program of the Bill &amp; Melinda Gates Foundation. If you have any suggestions or comments, please let me know. "],
["section-ch-introduction2.html", "Chapter 1 Introduction ", " Chapter 1 Introduction "],
["section-sdg-4-2-1-indicator.html", "1.1 SDG 4.2.1 indicator", " 1.1 SDG 4.2.1 indicator "],
["section-quick-scan-of-instruments.html", "1.2 Quick scan of instruments", " 1.2 Quick scan of instruments "],
["section-care-giver-vs-direct-assessment.html", "1.3 Care-giver vs direct assessment", " 1.3 Care-giver vs direct assessment "],
["section-individual-programmatic-population-settings.html", "1.4 Individual-programmatic-population settings", " 1.4 Individual-programmatic-population settings "],
["section-ch-data.html", "Chapter 2 Data", " Chapter 2 Data Booklet I D-score: Turning milestones into measurement highlighted the concepts and tools needed to obtain a quantitative score from milestones from an instrument. Once we have such a score, we may Compare development within the same child over time; Compare development of two children of the same age; Compare development of two children at different ages; Compare developmemt of groups of children at different ages; And so on… In practice, the problem is more complicated. There are about 150 different instruments to measure child development. (Fernald et al. 2017) In principle, one could apply the methodology of booklet I to each instrument separately. Every instrument would thus define its own quantitative scale. The problem with this approach is that measurements made on those scales cannot be compared to each other. More in particular, scores will be specific to the milestones, study samples, and the domain coverage of the particular instrument. In sum, we wouldn’t be able to compare development across instruments, a major impediment. What is needed instead is either Everybody uses the same instrument; We extract comparable scores from different instruments. Option 1 seems easy, but may effectively halt the science of measuring child development. Until we have the perfect instrument option 2 is the only realistic choice. In this booklet we aim to exploit the overlap between instruments to create comparable scores. For example, most instruments have milestones like Can stack two blocks, Is able to stand or Says baba. By carefully mapping out the similarities between instruments we are able constrain the statistical model in a sensible way. As a result, we can map different instruments onto the same scale. This chapter introduces the data that we use to illustrate our methodology. The data originates from a study by the Global Child Development Group (GCDG) gathering child development data from 16 cohorts. Overview of cohorts and instrument (2.1) Cohort descriptions (2.2) Instruments (2.3) GCDG working group members and data contributors (2.4) "],
["section-sec-gcdgoverview.html", "2.1 Overview of cohorts and instruments", " 2.1 Overview of cohorts and instruments The Global Child Development Group (GCDG) collected data from 16 cohorts. The objective of the study was to develop a population-based measure to monitor early child development across ages and countries. The requirements for inclusion were direct assessment of child development; availability of individual milestone scores; spanning ages between 0-5 years; availability of follow-up measures, at ages 5-10 years. The effort resulted in a database containing individual data from over 16,000 children from 11 countries. The world map below (Figure: 2.1) colours the countries included in the study. Figure 2.1: Coverage of countries included in the study. The GCDG data comprises of birth cohorts, impact evaluation studies and instrument evaluation studies. Table 2.1 displays a brief overview of the instruments used in each substudy. Table 2.1: Overview of instruments administered in the cohorts. Cohort by den gri bat vin ddi bar tep asq sbi Bangladesh x Brazil 1 x Brazil 2 x Chile 1 x Chile 2 x x China x Colombia 1 x Colombia 2 x x x x Ecuador x Ethiopia x Jamaica 1 x Jamaica 2 x Madagascar x Netherlands 1 x Netherlands 2 x South Africa x x x Section 2.2 briefly describes each cohort. Section 2.3 reviews the measurement instruments. "],
["section-sec-cohorts.html", "2.2 Cohort descriptions", " 2.2 Cohort descriptions The Bangladesh study (GCDG-BGD-7MO) was an impact evaluation study including 1862 children around the age of 18 months. The Bayley Scale for Infant and Toddler Development-II (by2) was administered and long-term follow-up data were available for the Wechsler Preschool and Primary Scale of Intelligence (WPPSI) at 5 years (Tofail et al. 2008). The Brazil 1 study (GCDG-BRA-1) was a birth-cohort with 3 measurement moments: 644 children at 3 months, 1412 children at 6 months and 1362 children at 12 months. In each round, the Denver Developmental Screening Test-II (den) was administered. Long-term follow-up data were available for the Wechsler Adult Intelligence Scale (WAIS) at 18 years (Victora et al. 2006). The Brazil 2 study (GCDG-BRA-2) was a birth-cohort with measurements of 3907 children at 12 months and 3869 children at 24 months. On both occasions the Battelle Development Inventory (bat) was administered (Moura et al. 2010). The Chile 1 study (GCDG-CHL-1) was an impact evaluation study of 128 children assessed at 6 months, 1732 children at 12 months and 279 at 18 months. The by1 was administered at each wave. Long-term follow-up data were available for the WPPSI at 5-6 years (Lozoff et al. 2003). The Chile 2 study (GCDG-CHL-2) was a brith-cohort of 4869 children who were administered the Battelle Developmental Inventory (bat) at 7-23 months and 9201 children who were administered the Test de Desarrollo Psicomotor (tep) at 24-58 months. For the latter group, follow-up data were available for the Peabody Picture Vocabulary Test (PPVT) at 5-6 years (Conteras and González 2015). The China study (GCDG-CHN) was an impact evaluation study that contained 990 children assessed with the by3 at 18 months (Lozoff et al. 2016). The Colombia 1 study (GCDG-COL-LT45M) was an impact evaluation study that comprised two waves, wave 1 contained 704 children at 12-24 months and wave 2 631 children at 24-41 months. The by3 was administered at each wave. Long-term follow-up data were available for PPVT at 4-6 years (Attanasio et al. 2014). The Colombia 2 study (GCDG-COL-LT42M) was an instrument validation study where all 1311 children aged 6-42 months were adminstered the by3. For a subgroup of 658 children the den, the Ages and Stages Questionnaire (asq) and the bat screener were administered as well. Long-term follow-up data were available for the Fifth Wechsler Intelligence Scale for Children (WISC-V) and the PPVT (Rubio-Codina et al. 2016). In Ecuador an impact evaluation study (GCDG-ECU) was performed for 667 childen between 0-35 months where the Barrera Moncada (bar) was administered. Long-term follow-up data were available for the PPVT at 5-8 and 9-12 years (Paxson and Schady 2010). The Ethiopia study (GCDG-ETH) was a birth-cohort with 193 children of 12 months in the first wave, 440 children of 30 months at the second wave and 456 children of 42 months at the third wave. At each wave the by3 was administered. Long-term follow-up data were available for the PPVT at 10-11 years (Hanlon et al. 2009). The Jamaica 1 study (GCDG-JAM-LBW) was an impact evaluation study were the Griffiths Mental Development Scales (gri) were administed to 225 children of 15 months at the first wave, and 218 children of 24 months at the second wave. Long-term follow-up data were available for WPPSI and PPVT at 6 years (Walker et al. 2004). The Jamaica 2 study (GCDG-JAM-STUNTED) was an impact evaluation study were the gri were administed to 159 children at 9-24 months, 21-36 months and at 33-48 months. Long-term follow-up data were available for sbi, Raven’s Coloured Progressive Matrices (Ravens), and PPVT at 7-8 years and the WAIS at 17-18 years (Grantham-McGregor et al. 1991). The Madagascar study (GCDG-MDG) was an impact evaluation study where the sbi was administered to 205 children aged 34-42 months. Long-term follow-up data were available for sbi and PPVT at 7-11 years (Fernald et al. 2011). The Netherlands 1 study (GCDG-NLD-SMOCC) was an instrument validation study with a total of 9 waves. At each wave the Dutch Developmental Instrument (ddi) (In the Netherlands known as Van Wiechenschema) was administered. The first wave included 1985 children at 1 month, wave 2 1807 childen at 2 months, wave 3 1963 children at 3 months, wave 4 1919 children at 6 months, wave 5 1881 children at 9 months, wave 6 1802 children at 12 months, wave 7 1776 children at 15 months, wave 8 1787 children at 18 months, and wave 9 1815 children at 24 months (Herngreen et al. 1992). The Netherlands 2 study (GCDG-NLD-2) was an instrument validation study with a total of five waves. At each wave the ddi was administered. Wave 1 included 1016 children at 24 months, wave 2 995 children at 30 months, wave 3 1592 children at 36 months, wave 4 1592 children at 42 months, and wave 5 1024 childen at 48 months (Doove 2010). The South Africa study (GCDG-ZAF) was a birth cohort with four waves. The first wave included 485 children and second wave 275 children, who were assessed at 6 and 12 months, respectively, with the by1 and the gri. The third wave included 1802 children and the fourth wave 1614 children, assessed at 24 and 48 months, respectively, with the Vineland Social Maturity Scale (vin) (Richter et al. 2007). "],
["section-sec-instruments.html", "2.3 Instruments", " 2.3 Instruments The Bayley Scales for Infant and Toddler Development (by1,by2, by3) aim to assess infants and toddlers, aged 1-42 months. The current version is the by3, but in GCDG cohorts earlier version were also used (i.e. by1 and by2) (Bayley 1969)(Bayley 1993)(Bayley 2006). The 326 items of the by3 measure three domains: Cognitive items, Motor items (with fine and gross motor items) and Language items (with expressive and receptive items). The by2 contains 277 items and has two additional subscales: Social-Emotional and Adaptive Behavior. by1 contains 229 items. The Denver Developmental Screening Test (den) is aimed to identify developmental problems in children up to age six. The 125 dichotomous test items are distributed over the age range from birth to six years. The Denver covers four domains: personal-social, fine motor and adaptive, language, and gross motor. The test items are all directly observed by an examiner and are not dependent on parent report (Frankenburg et al. 1992) (Frankenburg et al. 1990). The Griffiths Mental Development Scales (gri) measure the rate of development in infants and young children in six developmenal areas: locomotor, personal-social, hearing and language, eye and hand coordination, performance and practical reasoning (Griffiths 1967). The Battelle Developmental Inventory (bat) measures key developmental skills in children from birth to 7 years, 11 months. The instrument contains 450 items distributed over five domains: adaptive, personal-social, communication, motor, and cognitive (Newborg 2005). The Vineland Social Maturity Scale (vin) is a test to assess social competence. The instrument contains eight subscales that measure communication skills, general self-help ability, locomotion skills, occupation skills, self-direction, self-help eating, self-help dressing and socialization skills (Doll 1953). The Dutch Developmental Instrument (ddi) measures early child development during the ages 0-4 years. The instrument consists of 75 milestone items that are distributed over three domains: fine motor, adaptive, personal and social behavior; communication; and gross motor (Schlesinger-Was 1981). The Barrera Moncada (bar) is a Spanish instrument that measures the growth and psychological development of children (Barrera Moncada 1981). The Test de Desarrollo Psicomotor (tep) is an instrument to evaluate toddlers aged 2 to 5 years on their development. The items are distributed over three sub-tests: 16 items assess coordination; 24 items assess language skills and 12 items assess motor skills (Haeussler and Marchant 1999). The Ages and Stages Questionnaire (asq) measures developmental progress in children between 2 months and 5,5 years. The instrument assess development in five areas: personal social, gross motor, fine motor, problem solving and communication. The asq contains sets of 30 items in 21 age intervals and is completed by the caregiver (Squires and Bricker 2009). The Stanford Binet Intelligence Scales (sbi) is a cognitive ability and intelligence test to diagnose developmental deficiencies in young children. The items are distributed over five subtests: fluid reasoning, knowledge, quantative reasoning, visual-spatial processing and working memory (Roid 2003)(Hagen and Stattler 1986). "],
["section-sec-group.html", "2.4 GCDG working group members and data contributors", " 2.4 GCDG working group members and data contributors Maureen M. Black, RTI International and Department of Pediatrics, University of Maryland School of Medicine, Baltimore, MD, USA. Stef van Buuren, Netherlands Organization for Applied Scientific Research TNO, Leiden &amp; University of Utrecht, Utrecht, The Netherlands. Gary L. Darmstadt, Department of Pediatrics, Stanford University School of Medicine, USA. M. Caridad Araujo, Inter-American Development Bank, Washington DC, USA. Susan M. Chang, Caribbean Institute for Health Research, The University of the West Indies, Kingston, Jamaica. Bernice M. Doove, Envida JGZ, Maastricht, The Netherlands Iris Eekhout, The Netherlands Organization for Applied Scientific Research TNO, Leiden, The Netherlands. Lia C.H. Fernald, School of Public Health, University of California, Berkeley, CA, USA. Emanuela Galasso, The World Bank, Washington DC, USA. Sally Grantham-McGregor, Emerita Professor, Institute of Child Health, University College London, UK. Pamela Jervis, Centre for the Evaluation of Development Policies, The Institute for Fiscal Studies, UK. Jena D. Hamadani, International Centre for Diarrhoeal Disease Research, Bangladesh. Charlotte Hanlon, Centre for Global Mental Health, Health Services and Population Research Department, Institute of Psychiatry, Psychology and Neuroscience, King’s College London; Department of Psychiatry, School of Medicine, College of Health Sciences, Addis Ababa University, Ethiopia. Simone M. Karam, Medical Faculty, Department of Pediatrics, PPG Public Health, Federal University of Rio Grande, Brazil. Betsy Lozoff, Center for Human Growth and Development, University of Michigan, Ann Arbor, MI, USA. Orazio Attanasio, Department of Economics, University College London, UK. Girmay Medhin, Aklilu Lemma Institute of Pathobiology, Addis Ababa University, Addis Ababa, Ethiopia. Ana M. B. Menezes and the 1993 Pelotas cohort team, Postgraduate Program in Epidemiology, Federal University of Pelotas, Brazil. Helen Pitchik, School of Public Health, University of California, Berkeley, CA, USA. Lisy Ratsifandrihamanana, Centre Médico-Educatif “Les Orchidées Blanches”, Antananarivo, Madagascar. Sarah Reynolds, School of Public Health, University of California, Berkeley, CA, USA. Linda Richter, DST-NRF Centre of Excellence in Human Development, University of the Witwatersrand, Johannesburg, South Africa. Marta Rubio-Codina, Inter-American Development Bank, Washington DC, USA. Norbert Schady, Inter-American Development Bank, Washington DC, USA. Susan P. Walker, Caribbean Institute for Health Research, The University of the West Indies, Kingston, Jamaica. Ann M. Weber, Department of Pediatrics, Stanford University School of Medicine, Stanford, CA, USA. "],
["section-ch-comparability.html", "Chapter 3 Comparability", " Chapter 3 Comparability This chapter describes challenges and methodologies to harmonise child development measurements obtained by different instruments: Are instruments connected? (3.1) Bridging instruments by mapping items (3.2) Overview of promising item mappings (3.3) "],
["section-sec-challenge.html", "3.1 Are instruments connected?", " 3.1 Are instruments connected? The ultimate goal is to compare child development across populations and cultures. A complication is that measurements are made by different instruments. To do deal with this issue, we harmonise the data included in the GCDG cohorts. In particular, we process the milestone responses such that the following requirements hold: Every milestone in an instrument has a unique name and a descriptive label; Every milestone occupies one column in the dataset; Item scores are (re)coded as: 1 = PASS; 0 = FAIL; Items not administered or not answered are a missing value; Every row in the dataset corresponds to a unique cohort-child-age combination. Cohorts and milestones need to be connected. There are several ways to connect cohorts: Two cohorts are directly connected if they use the same instrument; Two cohorts are indirectly connected if both connect to a third cohort that connects them. Likewise, instruments can be connected: Two instruments are directly connected if the same cohort measures both; Two instruments are indirectly connected if both connect to a third instrument that connects them. Table 3.1: Linkage pattern indicating combinations of cohorts and instruments. aqi bar bat by1 by2 by3 ddi den gri mac peg sbi sgr tep vin Bangladesh X Brazil 1 X Brazil 2 X Chile 1 X Chile 2 X X China X Colombia 1 X Colombia 2 X X X X Ecuador X Ethiopia X Jamaica 1 X Jamaica 2 X Madagascar X X X Netherlds 1 X Netherlds 2 X S Africa X X X X An X in Table 3.1 identifies which cohorts use which instruments. The linkage table shows that studies from China, Colombia and Ethiopia are directly connected (by by3). Brazil 1 indirectly connects to these studies through den. Some cohorts (e.g., Chile 1 and Ecuador) do not link to any other study. Likewise, we might say that aqi, bat, by3 and den are directly connected. Note that no indirect connections exist to this instrument group. Table 3.1 is a somewhat simplified version of the linkage pattern. As we saw in section 2.2, there are substantial age differences between the cohorts. The table at https://tnochildhealthstatistics.shinyapps.io/GCDG_instrument_linkage/ shows the counts of the number of registered scores per age group. What appears in table 3.1 as one test may actually comprise of two disjoint subsets, and hence some cohorts may not be connected after all. Connectedness is a necessary - though not sufficient - requirement for parameter identification. If two cohorts are not connected, we cannot distinguish between the following two alternative explanations: Any differences between studies can be attributed to the ability of the children; Any differences between studies can be attributed to the difficulties of the instruments. The data do not contain the necessary information to discriminate between these two explanations. Since many cohorts in Table 3.1 are unconnected, it seems that we are stuck. The next section suggests a way out of the dilemma. "],
["section-sec-mapping.html", "3.2 Bridging instruments by mapping items", " 3.2 Bridging instruments by mapping items Many instruments for measuring child development have appeared since the works of Shirley (1933) and Gesell (1943). It is no surprise that their contents show substantial overlap. All tools assess events like starting to see, hear, smile, fetch, crawl, walk, speak and think. We will exploit the overlap to bridge different instruments. For example, Table 3.2 displays the labels of milestones from six instruments. All items probe the ability of the child to formulate “sentences” of two words. Table 3.2: Example of similar items from different instruments. Item Label by1mdd136 sentence of 2 words by2mdd114 Uses a two-word utterance ddicmm041 Says sentences with 2 words denlgd019 Combine Words grihsd217 Uses word combinations vinxxc016 use a short sentence The idea is to check whether these milestones measure development in the same way. If this is found to be accurate, then we may formally restrict the difficulty levels of these milestones to be identical. This restriction provides a formal bridge between the instruments. We repeat the process for all groups of similar-looking items. A first step in the bridging process is to group items from different instruments by similarity. As the by3 is relatively long and is the most often used instrument, it provides a convenient starting point. Subject matter experts experiences in child development mapped items from other tools to by3 items. These experts evaluated the similarity of wordings and descriptions in reference manuals. Also, they mapped same-skill items across other instruments into groups if these did not map onto by3 items. We order item mappings into five domains: fine motor (FM), gross motor (GM), cognitive (COG), receptive (REC) and expressive (EXP). Figure 3.1 displays the connections between the instruments (blue nodes) via the item groups in each domain. Figure 3.1: Connections between the instruments via mapped item groups. "],
["section-sec-viewmapping.html", "3.3 Overview of promising item mappings", " 3.3 Overview of promising item mappings The potential of item mappings is evaluated visually by plotting the probability to pass items for age for the item groups and compare the curves between cohorts. When the data shows similar patterns between items and cohorts, the item mapping can be tested in the modelling phase. In Figure 3.2, the probability to pass items for age is displayed for two potential bridges. The first plot presents a group of four cognitive items that assess the ability to put a cube or block in a cup or box. The items are administered in different studies and seem to work similarly. The second plot presents a group of six fine motor items that assess the ability to build a tower of six cubes or blocks. These items also seem to work similarly in the different cohorts. Figure 3.2: Probability to pass items for age in potential bridges. When the patterns of the plotted data differ between items and/or cohorts, the mapping might not be a good one after all. This can be due to differences between populations or because the items work differently in different populations (i.e. differential item functioning). The exact cause of the missmatch can be further investigated in the modelling phase. In Figure 3.3, two examples of poor item mappings are presented. Figure 3.3: Probability to pass items for age in poor bridges. "],
["section-ch-equategroups.html", "Chapter 4 Equate groups", " Chapter 4 Equate groups This chapter explains the equate group method. The equate group method is a novel method to link different instruments administered across multiple cohorts. Combining existing data sets for meta-analyses enables analyses across multiple contexts and conditions. Definition of equate groups (4.1) Concurrent calibration (4.2) Requirements of equate groups (4.3) Statistical framework (4.4) Common latent scale (4.5) Quantifying equate fit (4.6) Differential Item Functioning (4.7) "],
["section-sec-eqdef.html", "4.1 Definition of equate groups", " 4.1 Definition of equate groups A group of items that measure the same thing in (perhaps slightly) different ways is called an “equate group”. An equate group can link items across instruments by restricting their difficulty estimates to be identical. Equate groups provide an extra option for bridging different instruments to the same scale. Figure 4.1 displays items from three different instruments that measure child development. The instruments contain some common items that are measured in multiple instruments, but also unique items. The common items can be linked in an equate group as displayed by the arrows between them. In the example there is one (common) item that is equivalent in all three instruments (i.e. walk alone). The item “sitting” occurs in both the first ( i.e. blue) and the second (i.e. green) instrument and the item “clabs hand together” occurs in the second (i.e. green) and third (i.e. orange instrument). Figure 4.1: Example of three instruments that are bridged by common items in equate groups. "],
["section-sec-concurrent.html", "4.2 Concurrent calibration", " 4.2 Concurrent calibration When each instrument is administered in a different cohort, the cohorts can be linked by placing the common items in the same column. The common items will have the same difficulty estimates due to linking with “concurrent calibration”. In concurrent calibration the item parameters for all instruments are estimated simulateously. Concurrent calibration is an attractive option, however this method warrants a strict distinction between items that are truly the same in different instruments and items that differ. In practice, items that measure the same skill may have been adapted to suit the format of the instrument ( e.g. number of response options, question formulation, and so on) or to suit the local language and cultural context, which may or may not have an effect on the measurement properties of the instrument. This appeals to the possibility to explore and test different sets of equate items. Also, when in example Figure 4.1 the first and second instruments are both administered in the same cohort and the third in a second, concurrent calibration is not possible for common items in the first two instruments. In these situations, the equate group method is a more flexible way to link items. The equate groups methods works with similar assumptions as the concurrent calibration method, but with the flexibility to explore, test and modify the sets of equate items ( i.e. equate groups) used in the model. "],
["section-sec-equaterules.html", "4.3 Requirements of equate groups", " 4.3 Requirements of equate groups Statistical information and subject matter experts form the basis for the assignment of items to eligible equate groups. In actual modeling, there are “active” equate groups (i.e. equate groups for which the restriction is actually applied) and “passive” equate groups (i.e. similar items for which the restriction is not applied). Only active groups bridge the different instruments in the final model. The following strategies are recommended to select equate groups: As a first step, content experts can start by mapping similar items. For example use one instrument as a reference and map the items of other instruments to those items (see section 3.2). In a second step, the mapping can be visualized by plotting the mapped items in one figure (see section 3.3). That way, potential matches can be verified and confirmed if they show similar patterns or broken up if they seem poor mappings. In this step, both statistical and content expertise can be utilized. Next, the model can be fitted using a selection of potential matches as active equate groups. The technical details of this model are explained in section 4.4. The selection of the final active equate groups for the model is an iterative process where two important qualifications should be considered: (1) the active equate groups should link all cohorts and instruments. (2) To enhance the functioning of equate groups, the active equate groups are preferably distributed over the scale, rather than centered at one point. The infit and outfit can be calculated for equate groups, which provides a natural measure of equate group quality (see section 4.6). The performance of the equategroups across subgroups or cohorts can be tested with methods designed to detect differential item functioning (see section 4.7). In general, the use of equate groups is very relevant when the abilities differ across cohorts. In that case, equate groups are very helpful to place the abilities across the different cohorts on the same scale. However, when cohort abilities are relatively uniform and the risk of mis-specification of the equate groups is high, a model without equate groups is preferred. "],
["section-sec-statisticalframe.html", "4.4 Statistical framework", " 4.4 Statistical framework The preferred measurement model for development data is the Rasch model. An introduction of the Rasch model geared towards the \\(D\\)-score is described in https://stefvanbuuren.name/dbook1/. The Rasch model, models the probability of passing an item as a logistic function of the difference between each person’s ability and the difficulty of the item, see equation (4.1). \\[\\begin{equation} \\pi_{ni} = \\frac{exp(\\beta_n - \\delta_i)}{1+exp(\\beta_n -\\delta_i)} \\tag{4.1} \\end{equation}\\] The symbols used in equation (4.1) are explained in Table 4.1. The log odds that a person with ability \\(\\beta_n\\) answers an item with difficulty \\(\\delta_i\\) correctly is the difference between the person’s ability and the item’s difficulty \\((\\beta_n-\\delta_i)\\) (Wright and Masters 1982). In order to facilitate the use of equate groups to link similar items used in different instruments and cohorts, the Rasch model can be extended. This extension holds the restriction that item difficulties of similar items are constrained as equal. Wright and Masters (Wright and Masters 1982) present a simple method to equate the difficulty between two test forms that have common item links. This is done by estimating the shift in difficulty as the weighted average of difficulty differences of the linked items, and using this weighted average to align the difficulties of the test forms. We can use this way of aligning forms, to align item difficulties of items in an equate group, see equation (4.2). \\[\\begin{equation} \\delta_q = \\frac{\\sum_{l}^{i} \\delta_iw_i}{\\sum_{l}^{l} w_i} \\tag{4.2} \\end{equation}\\] Table 4.1: Overview the symbols used in equations (4.1) and (4.2). Symbol Term Description \\(\\beta_n\\) Ability True (but unknown) developmental score of child \\(n\\) \\(\\delta_i\\) Difficulty True (but unknown) difficulty of item \\(i\\) \\(\\delta_q\\) Difficulty The combined difficulty of the items in equate group \\(q\\) \\(\\pi_{ni}\\) Probability Probability that child \\(n\\) passes item \\(i\\) \\(l\\) The number of items in the equate group \\(w_i\\) The number of respondends with an observed score on item \\(i\\) "],
["section-sec-commonscale.html", "4.5 Common latent scale", " 4.5 Common latent scale The end goal for using the equate group method to model development items is to measure development on one common latent scale, the \\(D\\)-score. That way, the measure (i.e. \\(D\\)-score) can be obtained, irrespective of which instrument is used in which population. In Figure 4.2 the \\(D\\)-scores are displayed for three cohorts from the GCDG study: Netherlands 1 (GCDG-NLS-SMOCC), Ethiopia (GCDG-ETH) and Colombia 2 (GCDG-COL-LT42M). As decribed in section 2.2, the Netherlands 1 study contains the ddi; Ethiopia the by3; and Colombia the by3, den, asq and bdi. Accordingly there is some natural ovelap in items between Ethiopia and Colombia via the by3 items. However, the Netherlands 1 cohorts is not linked via the items. In the upper plot, no equate groups were used in the model and in the lower plot, equate groups linked the cohorts. Figure 4.2: Example of three cohorts with and without equage group linking. In the plot for the model without equate groups it can be observed that the scales for the Ethiopia and Colombia 2 studies are linked naturally via the shared items from by3. The Netherlands 1 cohort is not connected and follows a different track. In the plot for the model with equate groups, the scales for all three cohorts are connected. This example shows that the use of equate groups brings the abilities for children in different cohorts measured with different instrument on one scale. "],
["section-sec-equatefit.html", "4.6 Quantifying equate fit", " 4.6 Quantifying equate fit In the Rasch philosophy it is the task of the data to fit the Rasch model. In order to verify the fit of the data to the model, we can assess the item fit and the person fit. Both fit measures are explained thorougly in https://stefvanbuuren.name/dbook1/ch-evaluation.html. When we use equate groups in the Rasch model, we can also use these fit indices to determine the fit of the items in the equate groups. 4.6.1 Well fitting equate groups The evaluation of equate fit involves comparing the observed probabilities of endorsing the items in the equate group to the estimated probability of endorsing the items in the equate group. In an equate group there is an empirical curve for each item in the equate group and one shared estimated curve. The empirical curves should all be close to the estimiated curve for a good equate fit, as presented in the two examples in Figure 4.3. Figure 4.3: Two equate groups that present a good equate fit. The equate Turns head to sound of bell is asked in slightly different formats in the Bayley I (by1), Dutch Development Instrument (ddi) and the Denver (den). The three items are combined in an equate group and the empirical data are clored differently for each instrument in Figure 4.3. Equate Walks alone is administered in six different instruments (bar, by1, by2, by3, ddi and gri). For both equate groups, the empirical data for each instrument is close to the fitted dashed line, which indicates a good equate fit. The infit and outfit indices, shown in Figure4.3, confirm the good fit (fit &lt; 1). 4.6.2 Equate groups with poor equate fit In modeling with equate groups, selecting the perfect combination of equate groups is a crucial step. Poor fitting equate groups need to be set as passive equate groups, such that the items in the group are not restricted to the same difficulty anymore. In a poor fitting equate group the empirical curve for each item in the equate group are not close to the shared estimated curve. Additionally, the fit indices show poor fit as well (fit &gt; 1). Two examples of poor equate fit are shown in Figure 4.4. Figure 4.4: Two equate groups that present a poor equate fit. The equate Bangs in play / Bangs 2 blocks is asked in two different instruments, the Bayley I (by1) and the Denver (den). The empricial curve for the Bayley I item is not close to the fitted curve. The fitted curve is closer to the Denver item, which suggests that the equate difficulty is mostly based on the Denver item data. The fit indices are both larger than 1 also indicating the poor fit. The equate Jabbers expressively is asked in different forms in three instruments (i.e. by1, ddi, and gri). The empirical curves, with different colors for ech instrument, are not close to each other, nor close to the fitted curve. Also for this equate the fit indices confirm the poor fit (fit &gt; 1). Both equates should be deactivated in an updated model. "],
["section-sec-equatedif.html", "4.7 Differential item functioning", " 4.7 Differential item functioning An important assumption for equate groups is that the items in the group work in the same way across the different cohorts, i.e., there is no differential item functioning. This means that the items in the equate group are equally difficult for children in different cohorts. This assumption is critical for active equate groups. If it is not met, restricting the difficulty parameters as equal across cohorts may introduce unwanted bias in comparisons between cohorts. 4.7.1 Good equate group without DIF In Figure 4.5, two active equate groups are displayed with empirical curves in different colors for each cohort. In both equate groups the curves are close to each other and to the fitted dashed curve. The lack of difference between the curves for the differnt cohorts, shows that there is no different equate functioning (i.e. different item functioning, DIF) between the cohorts. Figure 4.5: Two equate groups that present no differential item functioning between cohorts. 4.7.2 Poor equate groups with DIF for study In Figure 4.6, two passive equate groups are displayed, that show differential item functioning between cohorts. The empirical curves are displayed for each cohort separately in different colors. The difference between these curves shows the differential item functioning. For example, the item Throws ball, is easier for children in the South-Africa cohort (purple curve; GCDG-ZAF), and more difficult for children in Colombia (blue curve; GCDG-COL-LT42M). In other words, the probability to pass the item given the D-score (i.e. item difficulty) differs between the cohorts. The same goes for the item Says more than 5 words, which is easier for childen in Jamaica (yellow and pink curves; GCDG-JAM-LBW and GCDG-JAM-SUNTED) and more difficult for children in Ecuador (green; GCDG-ECU). Figure 4.6: Two equate groups that present differential item functioning between cohorts. "],
["section-ch-modelingequates.html", "Chapter 5 Modeling equates ", " Chapter 5 Modeling equates "],
["section-gcdg-data-design-and-description.html", "5.1 GCDG data: design and description", " 5.1 GCDG data: design and description "],
["section-empirical-and-fitted-item-response-curves.html", "5.2 Empirical and fitted item response curves", " 5.2 Empirical and fitted item response curves "],
["section-active-and-non-active-equate-groups.html", "5.3 Active and non-active equate groups", " 5.3 Active and non-active equate groups "],
["section-splitting-and-combining-equate-groups.html", "5.4 Splitting and combining equate groups", " 5.4 Splitting and combining equate groups "],
["section-modeling-strategies.html", "5.5 modeling strategies", " 5.5 modeling strategies "],
["section-ch-ability.html", "Chapter 6 Comparing ability", " Chapter 6 Comparing ability In this chapter the \\(D\\)-score distributions per GCDG cohort are displayed and the impact of measurement error is compared between the cohorts. Additionally the coverage of the developmental domains is displayed for different levels of the \\(D\\)-score. D-score distribution by study (6.1) Impact of measurement error (6.2) Domain coverage (6.3) "],
["section-sec-dsores.html", "6.1 D-score distribution by study", " 6.1 D-score distribution by study For each study that is included in the GCDG assembly, the \\(D\\)-score can be obtained using the developed global model. In the graphs below, the \\(D\\)-score distributions are displayed for each cohort seperately. The blue lines in the graphs are the (temporary) references, as explained in (@(sec:references)). By using the “next” button below the plot you can click through the cohorts. Using the selection bar above the graph, you can select a specific cohort. "],
["section-sec-sem.html", "6.2 Impact of measurement error", " 6.2 Impact of measurement error For each estimated \\(D\\)-score from the calibrated model, the precision of the estimate can be determined. This precision can be expressed as the standard error of measurement (\\(sem\\)). The standard error of measurement is inversely related to the number of items. Thus, when more items are administered for a person, the measurement error for the \\(D\\)-score of this person will be smaller. As is shown in figure 6.1, the sem drops fast when the number of items is increased to 15, and still some more until the number of items is 30. More than 30 items has little effect on the sem. Figure 6.1: Standard error of measurement when the number of items increases. The precision of the \\(D\\)-score estimate is also affected by the information in the items that are administered. This is partly the number of items, as depicted in 6.1, but also if the items are informative for the \\(D\\)-score. For example, if the items are too easy and the probability to pass the item given the \\(D\\)-score is \\(P\\) &gt; 0.90, the \\(sem\\) is larger than when the difficulty of the administered items is closer to the \\(D\\)-score (i.e. \\(P\\) = 0.50). The sem for age in GCDG data shows that for some ages, the sem is larger than for others (see Figure 6.2). This is on the one hand due to the number of items available in that age range, but also to the design of the cohorts where sometimes relatively easy items are administered. Figure 6.2: Standard error of measurement in each age group. In Figure (@refStandard Error of Measurment for age by cohort), the \\(sem\\) per age group is shown for each cohort seperately. This illustrates the differences in design between the cohorts. For example, the Netherlands 1 cohort (GCDG-NLD-SMOCC), the ddi was used as a screener and items had the probability to pass of approximately \\(P\\)=0.80 (quartile range between 0.62 &lt; \\(P\\) &gt; 1.00), and the number of items administered per measurement is about 10 items (quartile range 6 to 12 items). The Colombia 1 cohort (GCDG-COL-LT45M) was an impact evaluation and has administered the by3 where each child answered on average 45 items (quartile range 38 to 57 items) and the probablity to pass was approximately \\(P\\) = 0.64 (quartile range betweeen 0.53 &lt; \\(P\\) &gt; 0.79). The latter study has therefore more precise \\(D\\)-score estimates. The \\(sem\\) for an entire cohort or sample can be obtained by pooling the individual \\(sem_i\\) using general rule for pooling variances. Accordingly, the \\(sem\\) for a sample is obtained by combining the within variance \\(\\sum{sem_{i}^2}\\) and the between variance \\(\\sigma_d\\) as in equation (6.1) \\[\\begin{equation} sem = \\sqrt{\\frac{\\sum{sem_{i}^2} + \\sigma_d }{N-1}} \\tag{6.1} \\end{equation}\\] In Figure 6.3 the sample \\(sem\\) per cohort are displayed. The lowest sample \\(sem\\) is found in the Ethiopia study (GCDG-ETH) and the highest in the South Africa cohort (GCDG-ZAF). This can be explained on the one hand by the number of items per child, and on the other hand the difficulty of the administered items. Table 6.1 shows the quartile ranges for the number of items per child (n) and the probability to pass the items (p). In The Ethiopia cohort 39 items (Q2; median) were administered with a median probability of 0.66 and in the South Africa study just 12 items with a median probability of 1. Accordingly, in the Ethiopia study more items were administered per child that also have a high level of information for the \\(D\\)-score. In the South Africa study only few items were administered per child that were also relatively easy and therefore contained less information for the \\(D\\)-score. Figure 6.3: Standard Error of Measurement per cohort. Table 6.1: Quartiles for the number of items (n) and probability to pass the items (p) per cohort cohort n Q1(0.25) n Q2(0.50) n Q3(0.75) p Q1(0.25) p Q2(0.50) p Q3(0.75) GCDG-ETH 29 39 47 0.54 0.66 0.75 GCDG-CHL-1 28 32 33 0.59 0.67 0.76 GCDG-COL-LT45M 38 45 57 0.53 0.64 0.79 GCDG-COL-LT42M 47 61 75 0.52 0.62 0.76 GCDG-JAM-LBW 40 43 46 0.50 0.55 0.60 GCDG-CHN 26 27 31 0.45 0.50 0.54 GCDG-JAM-STUNTED 31 38 46 0.58 0.65 0.72 GCDG-CHL-2 33 33 33 0.18 0.48 0.79 GCDG-BGD-7MO 14 14 15 0.27 0.38 0.43 GCDG-MDG 6 8 9 0.22 0.35 0.50 GCDG-BRA-1 16 18 18 0.81 0.89 0.94 GCDG-NLD-SMOCC 6 10 12 0.62 0.80 1.00 GCDG-NLD-2 5 11 17 0.85 1.00 1.00 GCDG-ECU 3 3 5 0.33 0.67 1.00 GCDG-ZAF 5 12 12 0.83 1.00 1.00 "],
["section-sec-domains.html", "6.3 Domain coverage", " 6.3 Domain coverage The \\(D\\)-score is a one number score that measures early child development. To evaluate the content validity of the \\(D\\)-score we can make sure that all developmental domains are fairly respresented. We distinguish five domains for child development: Motor development (motor), Cognitive development (cog), Language development (lang), Social-emotional (sem), and Life skills (life). The items can be linked to one or more domains and the cumulative item information for each domain can be evaluated. In Figure ??, the coverage of the domains for the \\(D\\)-score is displayed. This shows that at lower levels of the \\(D\\)-score, motor development is more dominant and that at higher levels of the \\(D\\)-score the cognitive van language domains increase in importance. It is possible to calculate a \\(D\\)-score that is more representative for a specific domain using the current \\(D\\)-score model. We can use only the items that load to the domain in question to calculate the \\(D\\)-score. "],
["section-ch-SDGindicator.html", "Chapter 7 SDG 4.2.1 Indicator", " Chapter 7 SDG 4.2.1 Indicator This chapter explains how the \\(D\\)-score can be used to indicate on-track development. The methodology to define on-track development is described and country-level estimates are displayed. Additionally the domain coverage of the \\(D\\)-score is discussed and comparisons to other estimates. Application I: Estimating the SDG 4.2.1 indicator from existing data (7.1) Definition developmentally on track (??) Country-level estimates (@refsec:countrytrack)) Domain coverage (@refsec:domains)) Relation to other estimates (@refsec:otherestimates)) "],
["section-sec-application1.html", "7.1 Application I: Estimating the SDG 4.2.1 indicator from existing data", " 7.1 Application I: Estimating the SDG 4.2.1 indicator from existing data Sustainable Development Goal number 4 is to ensure inclusive an equitable quality education and promote lifelong learning opportunities for all. Target 4.2 holds that by 2030, ensure that all girls and boys have access to quality early childhood development, care and pre-primary education so that they are ready for primary eductation. Indicator 4.2.1 is to measure the proportion of children under 5 years of age who are developmentally on track in health, learning and psychosoical well-beying, by sex. Figure 7.1: Sustainable Development Goal 4. The \\(D\\)-score can be obtained from any instrument that is included in the calibrations for the score. This makes the \\(D\\)-score suited as a global score for development. Accordingly, the \\(D\\)-score can be used for the SDG 4.2.1 indicator and interpreted as the global measure for development. In the cohorts that are currently included in the GCDG study, a wide range of countries are represented 2.1. Combining existing data from such a wide range of countries to create the \\(D\\)-score, broadens the interpretation of the \\(D\\)-score. Nevertheless, for obtaining accurate references that represent world-wide population, more representative (existing) data needs to be added. "],
["section-definition-developmentally-on-track-secreferences.html", "7.2 Definition developmentally on track (#sec:references)", " 7.2 Definition developmentally on track (#sec:references) For child growth, (global) standards are published by the World Health Orgnaization (WHO) that are used to monitor growth in childen and to define whether children are on track. Growth standards are defined for weight-for-age, length/height-for age, weight-for-length/height, etc. In 2006, the methods for constructing a growth reference were reviewed by statisticians and growth experts that resulted in an advised strategy for constructing growth standard (Borghi et al. 2006). A similar strategy can be used to construct a reference standard child develpment-for-age. This reference standard can then be used to determine whether children are developmentally on track. In Figure @ref\\(D\\)-score reference contruction and translation to on-track development., the strategy for constructing standards for development and to use them to define on track dvelopment is explained in several steps. In the first step the D-score is plotted by age and in the subsequent steps, this relation is modelled in an an LMS model. The goal of an LMS model is to describe the relation of the \\(D\\)-score by age with age-conditional z-scores. This is done by three smoothed curves representing the median, coefficient of variation and the skewness. The resulting age standardized scores for development (daz), are then used to define on-track development. So D-scores within 2 standard deviations from the mean can be defines as on-track. Scores that are outside this range, are off-track. Note that the current reference is based on the GCDG study. The cohorts that are currently included are representing a wide range of countries. However, they are not representative for a global population. The current reference standards are therefore temporary and should be improved when more data are available. "],
["section-sec-countrytrack.html", "7.3 Country-level estimates", " 7.3 Country-level estimates For each age-\\(D\\)-score combination, a daz can be calculated. That way we can calculate the daz in each country that is included in the current GCDG study. By using the -2SD rule, we can obtain the percentage on-track development in each country. # A tibble: 11 x 2 country `on-track` &lt;chr&gt; &lt;dbl&gt; 1 BGD 0.949 2 BRA 0.995 3 CHL 0.983 4 CHN 0.999 5 COL 0.989 6 ECU 0.939 7 ETH 0.994 8 JAM 0.996 9 MDG 0.966 10 NLD 0.968 11 ZAF 0.974 "],
["section-sec-otherestimates.html", "7.4 Relation to other estimates", " 7.4 Relation to other estimates "],
["section-ch-ontrack.html", "Chapter 8 Who is on-track? ", " Chapter 8 Who is on-track? "],
["section-application-ii-what-determines-who-is-developmentally-on-track.html", "8.1 Application II: What determines who is developmentally on-track?", " 8.1 Application II: What determines who is developmentally on-track? "],
["section-types-of-explanatory-factors.html", "8.2 Types of explanatory factors", " 8.2 Types of explanatory factors "],
["section-relative-importance.html", "8.3 Relative importance", " 8.3 Relative importance "],
["section-opportunities-for-intervention.html", "8.4 Opportunities for intervention", " 8.4 Opportunities for intervention "],
["section-ch-discussion2.html", "Chapter 9 Discussion ", " Chapter 9 Discussion "],
["section-potential-and-limitations-of-existing-data-for-sdg-4-2-1.html", "9.1 Potential and limitations of existing data for SDG 4.2.1", " 9.1 Potential and limitations of existing data for SDG 4.2.1 "],
["section-options-for-improving-health-policy.html", "9.2 Options for improving health policy", " 9.2 Options for improving health policy "],
["section-suitability-of-d-score-metric.html", "9.3 Suitability of D-score metric", " 9.3 Suitability of D-score metric "],
["section-suggestions-for-better-measurement.html", "9.4 Suggestions for better measurement", " 9.4 Suggestions for better measurement "],
["section-references.html", "References", " References Attanasio, Orazio P, Camila Fernández, Emla O A Fitzsimons, Sally M Grantham-McGregor, Costas Meghir, and Marta Rubio-Codina. 2014. “Using the infrastructure of a conditional cash transfer program to deliver a scalable integrated early child development program in Colombia: cluster randomized controlled trial.” BMJ (Clinical Research Ed.) 349 (sep29 5): g5785. https://doi.org/10.1136/bmj.g5785. Barrera Moncada, G. 1981. “Crecimiento Y Desarrollo Psicológico Del Niño Venezolano.” Ediciones psicopediátricas. Caracas. Bayley, N. 1969. “Bayley Scales of Infant Development.” New York: Psychological Corp. ———. 1993. “The Bayley Scales of Infant Development-Ii.” San Antonio, TX: Psychological Corporation. ———. 2006. “Bayley Scales of Infant and Toddler Development–Third Edition: Technical Manual.” San Antonio, TX: Harcourt Assessment. Borghi, E, M de Onis, C Garza, J Van den Broeck, E A Frongillo, L Grummer-Strawn, S Van Buuren, et al. 2006. “Construction of the World Health Organization child growth standards: selection of methods for attained growth curves.” Statistics in Medicine 25 (2): 247–65. https://doi.org/10.1002/sim.2227. Conteras, D., and S. González. 2015. “Determinants of early child development in Chile: Health, cognitive and demographic factors.” International Journal of Education and Development 40: 217–30. Doll, E.A. 1953. “The Measurement of Social Competence: A Manual for the Vineland Social Maturity Scale.” Educational Test Bureau, Educational Publishers. Doove, B.M. 2010. “Ontwikkeling kinderen in Maastricht en Heuvelland (MOM), Evaluatie integraal kindvolgsysteem voor signalering in de Jeugdgezondheidszorg: MOMknowsbest.” Maastricht, Netherlands. Fernald, L.C.H., E. Prado, P. Kariger, and A. Raikes. 2017. “A Toolkit for Measuring Early Childhood Development in Low and Middle-Income Countries.” World Bank. Fernald, Lia C H, Ann Weber, Emanuela Galasso, and Lisy Ratsifandrihamanana. 2011. “Socioeconomic gradients and child development in a very low income population: evidence from Madagascar.” Developmental Science 14 (4): 832–47. https://doi.org/10.1111/j.1467-7687.2010.01032.x. Frankenburg, W.K., J. Dodds, P. Archer, H. Shapiro, and Bresnick B. 1992. “The Denver Ii: A Major Revision and Restandardization of the Denver Developmental Screening Test.” Pediatrics 89. Am Acad Pediatrics: 91–98. Frankenburg, W.K., J. Dodds, P. Archer, H. Shapiro, and B. Bresnick. 1990. “The Denver Ii Technical Manual.” Denver, CO: Denver Developmental Materials. Gesell, A. 1943. Infant and Child in the Culture of Today. Los Angeles, CA: Read Book Ltd. Grantham-McGregor, S M, C A Powell, S P Walker, and J H Himes. 1991. “Nutritional supplementation, psychosocial stimulation, and mental development of stunted children: the Jamaican Study.” Lancet (London, England) 338 (8758): 1–5. https://doi.org/10.1016/0140-6736(91)90001-6. Griffiths, R. 1967. “The Abilities of Babies: A Study in Mental Measurement.” University of London Press. Haeussler, I.M., and T. Marchant. 1999. “Tepsi: Test de Desarrollo Psicomotor 2-5 Años.” Eds. Universidad Católica de Chiles. Hagen, E., and J. Stattler. 1986. “Stanford–Binet Intelligence Scales, Fourth Edition.” Thorndike. Hanlon, Charlotte, Girmay Medhin, Atalay Alem, Fikru Tesfaye, Zufan Lakew, Bogale Worku, Michael Dewey, et al. 2009. “Impact of antenatal common mental disorders upon perinatal outcomes in Ethiopia: the P-MaMiE population-based cohort study.” Tropical Medicine &amp; International Health 14 (2): 156–66. https://doi.org/10.1111/j.1365-3156.2008.02198.x. Herngreen, W. P., J. D. Reerink, B. M. van Noord-Zaadstra, S. P. Verloove-Vanhorick, and J. H. Ruys. 1992. “The Smocc-Study: Design of a Representative Cohort of Live-Born Infants in the Netherlands.” European Journal of Public Health 2: 117–22. Lozoff, Betsy, Isidora De Andraca, Marcela Castillo, Julia B Smith, Tomas Walter, and Paulina Pino. 2003. “Behavioral and developmental effects of preventing iron-deficiency anemia in healthy full-term infants.” Pediatrics 112 (4): 846–54. http://www.ncbi.nlm.nih.gov/pubmed/14523176. Lozoff, Betsy, Yaping Jiang, Xing Li, Min Zhou, Blair Richards, Guobin Xu, Katy M Clark, et al. 2016. “Low-Dose Iron Supplementation in Infancy Modestly Increases Infant Iron Status at 9 Mo without Decreasing Growth or Increasing Illness in a Randomized Clinical Trial in Rural China.” The Journal of Nutrition 146 (3): 612–21. https://doi.org/10.3945/jn.115.223917. Moura, Danilo R, Jaderson C Costa, Iná S Santos, Aluísio J D Barros, Alicia Matijasevich, Ricardo Halpern, Samuel Dumith, Simone Karam, and Fernando C Barros. 2010. “Natural history of suspected developmental delay between 12 and 24 months of age in the 2004 Pelotas birth cohort.” Journal of Paediatrics and Child Health 46 (6): 329–36. https://doi.org/10.1111/j.1440-1754.2010.01717.x. Newborg, J. 2005. “Battelle Developmental Inventory-2nd Edition.” Rolling Meadows, IL: Riverside Publishing. Paxson, Christina, and Norbert Schady. 2010. “Does money matter? The effects of cash transfers on child development in rural Ecuador.” Economic Development and Cultural Change 59 (1): 187–229. http://www.ncbi.nlm.nih.gov/pubmed/20821896. Richter, Linda, Shane Norris, John Pettifor, Derek Yach, and Noel Cameron. 2007. “Cohort Profile: Mandela’s children: the 1990 Birth to Twenty study in South Africa.” International Journal of Epidemiology 36 (3): 504–11. https://doi.org/10.1093/ije/dym016. Roid, G.H. 2003. “Stanford–Binet Intelligence Scales, Fifth Edition.” WPS Psychological Tests. Rubio-Codina, Marta, M Caridad Araujo, Orazio Attanasio, Pablo Muñoz, and Sally Grantham-McGregor. 2016. “Concurrent Validity and Feasibility of Short Tests Currently Used to Measure Early Childhood Development in Large Scale Studies.” Edited by David O. Carpenter. PloS One 11 (8): e0160962. https://doi.org/10.1371/journal.pone.0160962. Schlesinger-Was, E.A. 1981. “Ontwikkelingsonderzoek van Zuigelingen En Kleuters Op Het Consultatiebureau.” Shirley, M. M. 1933. The First Two Years: A Study of Twenty-Five Babies. Vol. II: Intellectual Development. Minneapolis: University of Minnesota Press. Squires, J., and D. Bricker. 2009. “Ages &amp; Stages Questionnaires, Third Edition (Asq- 3). A Parent-Completed Child-Monitoring System.” Paul H. Brookes Publishing Co., Baltimore. Tofail, Fahmida, Lars Åke Persson, Shams El Arifeen, Jena D Hamadani, Ferdina Mehrin, Deborah Ridout, Eva-Charlotte Ekström, Syed N Huda, and Sally M Grantham-McGregor. 2008. “Effects of prenatal food and micronutrient supplementation on infant development: a randomized trial from the Maternal and Infant Nutrition Interventions, Matlab (MINIMat) study.” The American Journal of Clinical Nutrition 87 (3): 704–11. https://doi.org/10.1093/ajcn/87.3.704. Victora, Cesar Gomes, Cora Luiza Pavin Araújo, Ana Maria Batista Menezes, Pedro Curi Hallal, Maria de Fátima Vieira, Marilda Borges Neutzling, Helen Gonçalves, et al. 2006. “Methodological aspects of the 1993 Pelotas (Brazil) Birth Cohort Study.” Revista de Saude Publica 40 (1): 39–46. https://doi.org/10.1590/s0034-89102006000100008. Walker, Susan P, Susan M Chang, Christine A Powell, and Sally M Grantham-McGregor. 2004. “Psychosocial intervention improves the development of term low-birth-weight infants.” The Journal of Nutrition 134 (6): 1417–23. https://doi.org/10.1093/jn/134.6.1417. Wright, B. D., and G. N. Masters. 1982. Rating Scale Analysis: Rasch Measurement. Chicago: MESA Press. "]
]
